{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 11:39:47.811340: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.metrics import F1Score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_nose</th>\n",
       "      <th>y_nose</th>\n",
       "      <th>z_nose</th>\n",
       "      <th>x_left_eye_inner</th>\n",
       "      <th>y_left_eye_inner</th>\n",
       "      <th>z_left_eye_inner</th>\n",
       "      <th>x_left_eye</th>\n",
       "      <th>y_left_eye</th>\n",
       "      <th>z_left_eye</th>\n",
       "      <th>x_left_eye_outer</th>\n",
       "      <th>...</th>\n",
       "      <th>z_left_heel</th>\n",
       "      <th>x_right_heel</th>\n",
       "      <th>y_right_heel</th>\n",
       "      <th>z_right_heel</th>\n",
       "      <th>x_left_foot_index</th>\n",
       "      <th>y_left_foot_index</th>\n",
       "      <th>z_left_foot_index</th>\n",
       "      <th>x_right_foot_index</th>\n",
       "      <th>y_right_foot_index</th>\n",
       "      <th>z_right_foot_index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pose_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.889507</td>\n",
       "      <td>-57.637520</td>\n",
       "      <td>-45.019750</td>\n",
       "      <td>-4.656085</td>\n",
       "      <td>-62.832863</td>\n",
       "      <td>-44.571823</td>\n",
       "      <td>-3.302626</td>\n",
       "      <td>-63.386856</td>\n",
       "      <td>-44.567863</td>\n",
       "      <td>-2.032406</td>\n",
       "      <td>...</td>\n",
       "      <td>56.852562</td>\n",
       "      <td>-0.842025</td>\n",
       "      <td>35.037060</td>\n",
       "      <td>50.565020</td>\n",
       "      <td>5.842190</td>\n",
       "      <td>45.971020</td>\n",
       "      <td>50.263714</td>\n",
       "      <td>0.092779</td>\n",
       "      <td>45.842150</td>\n",
       "      <td>41.427795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.255504</td>\n",
       "      <td>-62.935925</td>\n",
       "      <td>-128.907500</td>\n",
       "      <td>-2.977403</td>\n",
       "      <td>-67.035990</td>\n",
       "      <td>-124.258545</td>\n",
       "      <td>-2.215265</td>\n",
       "      <td>-67.198250</td>\n",
       "      <td>-124.263240</td>\n",
       "      <td>-1.494903</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.129170</td>\n",
       "      <td>-1.298891</td>\n",
       "      <td>54.733307</td>\n",
       "      <td>-6.886051</td>\n",
       "      <td>3.980098</td>\n",
       "      <td>65.370830</td>\n",
       "      <td>-49.023930</td>\n",
       "      <td>-5.090634</td>\n",
       "      <td>65.641780</td>\n",
       "      <td>-42.878056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.878917</td>\n",
       "      <td>-61.709988</td>\n",
       "      <td>-137.453340</td>\n",
       "      <td>-1.619050</td>\n",
       "      <td>-65.693750</td>\n",
       "      <td>-132.181660</td>\n",
       "      <td>-0.785822</td>\n",
       "      <td>-65.814340</td>\n",
       "      <td>-132.184070</td>\n",
       "      <td>-0.019743</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.904400</td>\n",
       "      <td>-2.119770</td>\n",
       "      <td>51.265694</td>\n",
       "      <td>-15.554097</td>\n",
       "      <td>1.994894</td>\n",
       "      <td>62.725025</td>\n",
       "      <td>-57.717957</td>\n",
       "      <td>-4.452602</td>\n",
       "      <td>62.494457</td>\n",
       "      <td>-53.804527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.242575</td>\n",
       "      <td>-60.371220</td>\n",
       "      <td>-135.094830</td>\n",
       "      <td>-3.118133</td>\n",
       "      <td>-64.416000</td>\n",
       "      <td>-129.995930</td>\n",
       "      <td>-2.369744</td>\n",
       "      <td>-64.603290</td>\n",
       "      <td>-130.003400</td>\n",
       "      <td>-1.753780</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.855729</td>\n",
       "      <td>-1.485475</td>\n",
       "      <td>59.729427</td>\n",
       "      <td>1.433403</td>\n",
       "      <td>1.950102</td>\n",
       "      <td>68.187256</td>\n",
       "      <td>-42.989098</td>\n",
       "      <td>-4.573338</td>\n",
       "      <td>68.144350</td>\n",
       "      <td>-34.117043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.805543</td>\n",
       "      <td>-56.178570</td>\n",
       "      <td>-41.124413</td>\n",
       "      <td>-0.055174</td>\n",
       "      <td>-58.501305</td>\n",
       "      <td>-37.938560</td>\n",
       "      <td>0.456936</td>\n",
       "      <td>-58.473960</td>\n",
       "      <td>-37.954430</td>\n",
       "      <td>0.969290</td>\n",
       "      <td>...</td>\n",
       "      <td>47.124107</td>\n",
       "      <td>-2.455719</td>\n",
       "      <td>52.861732</td>\n",
       "      <td>45.936783</td>\n",
       "      <td>2.699764</td>\n",
       "      <td>57.254112</td>\n",
       "      <td>27.531416</td>\n",
       "      <td>-2.288348</td>\n",
       "      <td>57.803005</td>\n",
       "      <td>26.288315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x_nose     y_nose      z_nose  x_left_eye_inner  y_left_eye_inner  \\\n",
       "pose_id                                                                        \n",
       "0       -5.889507 -57.637520  -45.019750         -4.656085        -62.832863   \n",
       "1       -4.255504 -62.935925 -128.907500         -2.977403        -67.035990   \n",
       "2       -2.878917 -61.709988 -137.453340         -1.619050        -65.693750   \n",
       "3       -4.242575 -60.371220 -135.094830         -3.118133        -64.416000   \n",
       "4       -0.805543 -56.178570  -41.124413         -0.055174        -58.501305   \n",
       "\n",
       "         z_left_eye_inner  x_left_eye  y_left_eye  z_left_eye  \\\n",
       "pose_id                                                         \n",
       "0              -44.571823   -3.302626  -63.386856  -44.567863   \n",
       "1             -124.258545   -2.215265  -67.198250 -124.263240   \n",
       "2             -132.181660   -0.785822  -65.814340 -132.184070   \n",
       "3             -129.995930   -2.369744  -64.603290 -130.003400   \n",
       "4              -37.938560    0.456936  -58.473960  -37.954430   \n",
       "\n",
       "         x_left_eye_outer  ...  z_left_heel  x_right_heel  y_right_heel  \\\n",
       "pose_id                    ...                                            \n",
       "0               -2.032406  ...    56.852562     -0.842025     35.037060   \n",
       "1               -1.494903  ...   -14.129170     -1.298891     54.733307   \n",
       "2               -0.019743  ...   -19.904400     -2.119770     51.265694   \n",
       "3               -1.753780  ...    -6.855729     -1.485475     59.729427   \n",
       "4                0.969290  ...    47.124107     -2.455719     52.861732   \n",
       "\n",
       "         z_right_heel  x_left_foot_index  y_left_foot_index  \\\n",
       "pose_id                                                       \n",
       "0           50.565020           5.842190          45.971020   \n",
       "1           -6.886051           3.980098          65.370830   \n",
       "2          -15.554097           1.994894          62.725025   \n",
       "3            1.433403           1.950102          68.187256   \n",
       "4           45.936783           2.699764          57.254112   \n",
       "\n",
       "         z_left_foot_index  x_right_foot_index  y_right_foot_index  \\\n",
       "pose_id                                                              \n",
       "0                50.263714            0.092779           45.842150   \n",
       "1               -49.023930           -5.090634           65.641780   \n",
       "2               -57.717957           -4.452602           62.494457   \n",
       "3               -42.989098           -4.573338           68.144350   \n",
       "4                27.531416           -2.288348           57.803005   \n",
       "\n",
       "         z_right_foot_index  \n",
       "pose_id                      \n",
       "0                 41.427795  \n",
       "1                -42.878056  \n",
       "2                -53.804527  \n",
       "3                -34.117043  \n",
       "4                 26.288315  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features = pd.read_csv(filepath_or_buffer='training_data/landmarks.csv',\n",
    "                 index_col='pose_id')\n",
    "\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pose</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pose_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jumping_jacks_down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jumping_jacks_down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jumping_jacks_down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jumping_jacks_down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jumping_jacks_down</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       pose\n",
       "pose_id                    \n",
       "0        jumping_jacks_down\n",
       "1        jumping_jacks_down\n",
       "2        jumping_jacks_down\n",
       "3        jumping_jacks_down\n",
       "4        jumping_jacks_down"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = pd.read_csv(filepath_or_buffer='training_data/labels.csv',\n",
    "                        index_col='pose_id')\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_size, filters=8, dropout1=0.2, dropout2=0.2, classes=10):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_size,)),\n",
    "        Dense(filters, activation='relu'),\n",
    "        Dense(filters, activation='relu'),\n",
    "        Dense(filters, activation='relu'),\n",
    "        Dense(filters, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout1),\n",
    "        Dense(filters, activation='relu'),\n",
    "        Dense(filters, activation='relu'),\n",
    "        Dense(filters, activation='relu'),\n",
    "        Dense(filters, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout2),\n",
    "        Dense(classes, activation='softmax'),\n",
    "    ])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_early(patience=10, start=50):\n",
    "    earlystopping=EarlyStopping(monitor='val_f1_score',\n",
    "                                patience=patience,\n",
    "                                verbose=1,\n",
    "                                mode='max',\n",
    "                                restore_best_weights=True,\n",
    "                                start_from_epoch=start)\n",
    "    return earlystopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_poses = pd.read_csv(filepath_or_buffer='training_data/pose_landmarks_per_pose.csv').drop('Frame', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 719 entries, 0 to 718\n",
      "Data columns (total 99 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Nose_X            719 non-null    float64\n",
      " 1   Nose_Y            719 non-null    float64\n",
      " 2   Nose_Z            719 non-null    float64\n",
      " 3   LeftEyeInner_X    719 non-null    float64\n",
      " 4   LeftEyeInner_Y    719 non-null    float64\n",
      " 5   LeftEyeInner_Z    719 non-null    float64\n",
      " 6   LeftEye_X         719 non-null    float64\n",
      " 7   LeftEye_Y         719 non-null    float64\n",
      " 8   LeftEye_Z         719 non-null    float64\n",
      " 9   LeftEyeOuter_X    719 non-null    float64\n",
      " 10  LeftEyeOuter_Y    719 non-null    float64\n",
      " 11  LeftEyeOuter_Z    719 non-null    float64\n",
      " 12  RightEyeInner_X   719 non-null    float64\n",
      " 13  RightEyeInner_Y   719 non-null    float64\n",
      " 14  RightEyeInner_Z   719 non-null    float64\n",
      " 15  RightEye_X        719 non-null    float64\n",
      " 16  RightEye_Y        719 non-null    float64\n",
      " 17  RightEye_Z        719 non-null    float64\n",
      " 18  RightEyeOuter_X   719 non-null    float64\n",
      " 19  RightEyeOuter_Y   719 non-null    float64\n",
      " 20  RightEyeOuter_Z   719 non-null    float64\n",
      " 21  LeftEar_X         719 non-null    float64\n",
      " 22  LeftEar_Y         719 non-null    float64\n",
      " 23  LeftEar_Z         719 non-null    float64\n",
      " 24  RightEar_X        719 non-null    float64\n",
      " 25  RightEar_Y        719 non-null    float64\n",
      " 26  RightEar_Z        719 non-null    float64\n",
      " 27  MouthLeft_X       719 non-null    float64\n",
      " 28  MouthLeft_Y       719 non-null    float64\n",
      " 29  MouthLeft_Z       719 non-null    float64\n",
      " 30  MouthRight_X      719 non-null    float64\n",
      " 31  MouthRight_Y      719 non-null    float64\n",
      " 32  MouthRight_Z      719 non-null    float64\n",
      " 33  LeftShoulder_X    719 non-null    float64\n",
      " 34  LeftShoulder_Y    719 non-null    float64\n",
      " 35  LeftShoulder_Z    719 non-null    float64\n",
      " 36  RightShoulder_X   719 non-null    float64\n",
      " 37  RightShoulder_Y   719 non-null    float64\n",
      " 38  RightShoulder_Z   719 non-null    float64\n",
      " 39  LeftElbow_X       719 non-null    float64\n",
      " 40  LeftElbow_Y       719 non-null    float64\n",
      " 41  LeftElbow_Z       719 non-null    float64\n",
      " 42  RightElbow_X      719 non-null    float64\n",
      " 43  RightElbow_Y      719 non-null    float64\n",
      " 44  RightElbow_Z      719 non-null    float64\n",
      " 45  LeftWrist_X       719 non-null    float64\n",
      " 46  LeftWrist_Y       719 non-null    float64\n",
      " 47  LeftWrist_Z       719 non-null    float64\n",
      " 48  RightWrist_X      719 non-null    float64\n",
      " 49  RightWrist_Y      719 non-null    float64\n",
      " 50  RightWrist_Z      719 non-null    float64\n",
      " 51  LeftPinky_X       719 non-null    float64\n",
      " 52  LeftPinky_Y       719 non-null    float64\n",
      " 53  LeftPinky_Z       719 non-null    float64\n",
      " 54  RightPinky_X      719 non-null    float64\n",
      " 55  RightPinky_Y      719 non-null    float64\n",
      " 56  RightPinky_Z      719 non-null    float64\n",
      " 57  LeftIndex_X       719 non-null    float64\n",
      " 58  LeftIndex_Y       719 non-null    float64\n",
      " 59  LeftIndex_Z       719 non-null    float64\n",
      " 60  RightIndex_X      719 non-null    float64\n",
      " 61  RightIndex_Y      719 non-null    float64\n",
      " 62  RightIndex_Z      719 non-null    float64\n",
      " 63  LeftThumb_X       719 non-null    float64\n",
      " 64  LeftThumb_Y       719 non-null    float64\n",
      " 65  LeftThumb_Z       719 non-null    float64\n",
      " 66  RightThumb_X      719 non-null    float64\n",
      " 67  RightThumb_Y      719 non-null    float64\n",
      " 68  RightThumb_Z      719 non-null    float64\n",
      " 69  LeftHip_X         719 non-null    float64\n",
      " 70  LeftHip_Y         719 non-null    float64\n",
      " 71  LeftHip_Z         719 non-null    float64\n",
      " 72  RightHip_X        719 non-null    float64\n",
      " 73  RightHip_Y        719 non-null    float64\n",
      " 74  RightHip_Z        719 non-null    float64\n",
      " 75  LeftKnee_X        719 non-null    float64\n",
      " 76  LeftKnee_Y        719 non-null    float64\n",
      " 77  LeftKnee_Z        719 non-null    float64\n",
      " 78  RightKnee_X       719 non-null    float64\n",
      " 79  RightKnee_Y       719 non-null    float64\n",
      " 80  RightKnee_Z       719 non-null    float64\n",
      " 81  LeftAnkle_X       719 non-null    float64\n",
      " 82  LeftAnkle_Y       719 non-null    float64\n",
      " 83  LeftAnkle_Z       719 non-null    float64\n",
      " 84  RightAnkle_X      719 non-null    float64\n",
      " 85  RightAnkle_Y      719 non-null    float64\n",
      " 86  RightAnkle_Z      719 non-null    float64\n",
      " 87  LeftHeel_X        719 non-null    float64\n",
      " 88  LeftHeel_Y        719 non-null    float64\n",
      " 89  LeftHeel_Z        719 non-null    float64\n",
      " 90  RightHeel_X       719 non-null    float64\n",
      " 91  RightHeel_Y       719 non-null    float64\n",
      " 92  RightHeel_Z       719 non-null    float64\n",
      " 93  LeftFootIndex_X   719 non-null    float64\n",
      " 94  LeftFootIndex_Y   719 non-null    float64\n",
      " 95  LeftFootIndex_Z   719 non-null    float64\n",
      " 96  RightFootIndex_X  719 non-null    float64\n",
      " 97  RightFootIndex_Y  719 non-null    float64\n",
      " 98  RightFootIndex_Z  719 non-null    float64\n",
      "dtypes: float64(99)\n",
      "memory usage: 556.2 KB\n"
     ]
    }
   ],
   "source": [
    "df_no_poses.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_poses['pose'] = 'no_pose'\n",
    "no_pose_labels = df_no_poses.pose\n",
    "df_no_poses=df_no_poses.drop('pose', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_poses.columns = df_features.columns\n",
    "df_features = pd.concat([df_features, df_no_poses], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.concat([df_labels, no_pose_labels], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jumping_jacks_down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jumping_jacks_down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jumping_jacks_down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jumping_jacks_down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jumping_jacks_down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>no_pose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>no_pose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>no_pose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>no_pose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>no_pose</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2091 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pose\n",
       "0     jumping_jacks_down\n",
       "1     jumping_jacks_down\n",
       "2     jumping_jacks_down\n",
       "3     jumping_jacks_down\n",
       "4     jumping_jacks_down\n",
       "...                  ...\n",
       "2086             no_pose\n",
       "2087             no_pose\n",
       "2088             no_pose\n",
       "2089             no_pose\n",
       "2090             no_pose\n",
       "\n",
       "[2091 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_features\n",
    "y = pd.get_dummies(df_labels, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=38, stratify=y)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">715</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m6,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)             │           \u001b[38;5;34m715\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,747</span> (143.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m36,747\u001b[0m (143.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,491</span> (142.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m36,491\u001b[0m (142.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2 = get_model(99, 64, 0.5, 0.5, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - f1_score: 0.1511 - loss: 0.6116 - val_f1_score: 0.1209 - val_loss: 0.4574\n",
      "Epoch 2/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.3254 - loss: 0.2989 - val_f1_score: 0.2572 - val_loss: 0.3953\n",
      "Epoch 3/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.3509 - loss: 0.2599 - val_f1_score: 0.3155 - val_loss: 0.3012\n",
      "Epoch 4/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.4130 - loss: 0.2248 - val_f1_score: 0.4904 - val_loss: 0.2347\n",
      "Epoch 5/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - f1_score: 0.4852 - loss: 0.1900 - val_f1_score: 0.5730 - val_loss: 0.1643\n",
      "Epoch 6/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.5128 - loss: 0.1702 - val_f1_score: 0.6162 - val_loss: 0.1256\n",
      "Epoch 7/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.5669 - loss: 0.1441 - val_f1_score: 0.7014 - val_loss: 0.1027\n",
      "Epoch 8/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.5832 - loss: 0.1405 - val_f1_score: 0.6970 - val_loss: 0.0952\n",
      "Epoch 9/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.5865 - loss: 0.1160 - val_f1_score: 0.7143 - val_loss: 0.0777\n",
      "Epoch 10/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - f1_score: 0.6242 - loss: 0.1158 - val_f1_score: 0.7450 - val_loss: 0.0740\n",
      "Epoch 11/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.6569 - loss: 0.1020 - val_f1_score: 0.6917 - val_loss: 0.0730\n",
      "Epoch 12/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.6555 - loss: 0.1061 - val_f1_score: 0.7287 - val_loss: 0.0675\n",
      "Epoch 13/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.6338 - loss: 0.1058 - val_f1_score: 0.7999 - val_loss: 0.0531\n",
      "Epoch 14/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.6497 - loss: 0.0962 - val_f1_score: 0.7976 - val_loss: 0.0564\n",
      "Epoch 15/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.6837 - loss: 0.0891 - val_f1_score: 0.7641 - val_loss: 0.0558\n",
      "Epoch 16/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - f1_score: 0.7059 - loss: 0.0868 - val_f1_score: 0.7955 - val_loss: 0.0521\n",
      "Epoch 17/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.6772 - loss: 0.0848 - val_f1_score: 0.8219 - val_loss: 0.0555\n",
      "Epoch 18/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.7247 - loss: 0.0813 - val_f1_score: 0.8269 - val_loss: 0.0537\n",
      "Epoch 19/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.7451 - loss: 0.0674 - val_f1_score: 0.7800 - val_loss: 0.0513\n",
      "Epoch 20/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.7548 - loss: 0.0683 - val_f1_score: 0.7846 - val_loss: 0.0607\n",
      "Epoch 21/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - f1_score: 0.7495 - loss: 0.0720 - val_f1_score: 0.8151 - val_loss: 0.0516\n",
      "Epoch 22/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.7486 - loss: 0.0713 - val_f1_score: 0.7898 - val_loss: 0.0584\n",
      "Epoch 23/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - f1_score: 0.7708 - loss: 0.0594 - val_f1_score: 0.8278 - val_loss: 0.0509\n",
      "Epoch 24/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.7481 - loss: 0.0614 - val_f1_score: 0.7947 - val_loss: 0.0569\n",
      "Epoch 25/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - f1_score: 0.7686 - loss: 0.0576 - val_f1_score: 0.8080 - val_loss: 0.0622\n",
      "Epoch 26/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.8023 - loss: 0.0556 - val_f1_score: 0.7914 - val_loss: 0.0558\n",
      "Epoch 27/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.7605 - loss: 0.0720 - val_f1_score: 0.8272 - val_loss: 0.0504\n",
      "Epoch 28/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - f1_score: 0.8008 - loss: 0.0551 - val_f1_score: 0.8091 - val_loss: 0.0485\n",
      "Epoch 29/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - f1_score: 0.8006 - loss: 0.0559 - val_f1_score: 0.8011 - val_loss: 0.0483\n",
      "Epoch 30/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - f1_score: 0.7881 - loss: 0.0576 - val_f1_score: 0.8053 - val_loss: 0.0478\n",
      "Epoch 31/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.7985 - loss: 0.0563 - val_f1_score: 0.8328 - val_loss: 0.0436\n",
      "Epoch 32/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - f1_score: 0.8389 - loss: 0.0427 - val_f1_score: 0.8049 - val_loss: 0.0597\n",
      "Epoch 33/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.8047 - loss: 0.0541 - val_f1_score: 0.7706 - val_loss: 0.0462\n",
      "Epoch 34/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.8385 - loss: 0.0424 - val_f1_score: 0.8342 - val_loss: 0.0456\n",
      "Epoch 35/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.8339 - loss: 0.0474 - val_f1_score: 0.8465 - val_loss: 0.0522\n",
      "Epoch 36/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - f1_score: 0.8071 - loss: 0.0493 - val_f1_score: 0.8327 - val_loss: 0.0397\n",
      "Epoch 37/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.7929 - loss: 0.0543 - val_f1_score: 0.8560 - val_loss: 0.0405\n",
      "Epoch 38/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.7805 - loss: 0.0564 - val_f1_score: 0.7581 - val_loss: 0.0570\n",
      "Epoch 39/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.8329 - loss: 0.0438 - val_f1_score: 0.8055 - val_loss: 0.0424\n",
      "Epoch 40/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.7731 - loss: 0.0544 - val_f1_score: 0.8064 - val_loss: 0.0489\n",
      "Epoch 41/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.7479 - loss: 0.0726 - val_f1_score: 0.8241 - val_loss: 0.0436\n",
      "Epoch 42/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.7614 - loss: 0.0624 - val_f1_score: 0.8094 - val_loss: 0.0474\n",
      "Epoch 43/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.7993 - loss: 0.0571 - val_f1_score: 0.7630 - val_loss: 0.0507\n",
      "Epoch 44/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.7934 - loss: 0.0532 - val_f1_score: 0.8130 - val_loss: 0.0409\n",
      "Epoch 45/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.7817 - loss: 0.0691 - val_f1_score: 0.7999 - val_loss: 0.0371\n",
      "Epoch 46/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.7992 - loss: 0.0555 - val_f1_score: 0.8154 - val_loss: 0.0416\n",
      "Epoch 47/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.8235 - loss: 0.0476 - val_f1_score: 0.8800 - val_loss: 0.0312\n",
      "Epoch 48/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.8537 - loss: 0.0384 - val_f1_score: 0.8512 - val_loss: 0.0310\n",
      "Epoch 49/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.8370 - loss: 0.0406 - val_f1_score: 0.8422 - val_loss: 0.0327\n",
      "Epoch 50/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.8463 - loss: 0.0397 - val_f1_score: 0.8532 - val_loss: 0.0404\n",
      "Epoch 51/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.8052 - loss: 0.0469 - val_f1_score: 0.8681 - val_loss: 0.0431\n",
      "Epoch 52/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.8762 - loss: 0.0342 - val_f1_score: 0.8747 - val_loss: 0.0369\n",
      "Epoch 53/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.8791 - loss: 0.0312 - val_f1_score: 0.8374 - val_loss: 0.0386\n",
      "Epoch 54/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.8543 - loss: 0.0383 - val_f1_score: 0.8326 - val_loss: 0.0391\n",
      "Epoch 55/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.8854 - loss: 0.0307 - val_f1_score: 0.8506 - val_loss: 0.0346\n",
      "Epoch 56/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.8843 - loss: 0.0303 - val_f1_score: 0.8408 - val_loss: 0.0365\n",
      "Epoch 57/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.8251 - loss: 0.0435 - val_f1_score: 0.8794 - val_loss: 0.0339\n",
      "Epoch 58/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.8327 - loss: 0.0459 - val_f1_score: 0.8286 - val_loss: 0.0409\n",
      "Epoch 59/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.8649 - loss: 0.0299 - val_f1_score: 0.8624 - val_loss: 0.0408\n",
      "Epoch 60/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.8706 - loss: 0.0334 - val_f1_score: 0.8085 - val_loss: 0.0389\n",
      "Epoch 61/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.8699 - loss: 0.0316 - val_f1_score: 0.8629 - val_loss: 0.0391\n",
      "Epoch 62/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.8775 - loss: 0.0303 - val_f1_score: 0.8250 - val_loss: 0.0462\n",
      "Epoch 63/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.8668 - loss: 0.0312 - val_f1_score: 0.8244 - val_loss: 0.0417\n",
      "Epoch 64/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.8555 - loss: 0.0368 - val_f1_score: 0.7913 - val_loss: 0.0487\n",
      "Epoch 65/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.8416 - loss: 0.0366 - val_f1_score: 0.7995 - val_loss: 0.0425\n",
      "Epoch 66/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.8705 - loss: 0.0301 - val_f1_score: 0.8453 - val_loss: 0.0410\n",
      "Epoch 67/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.8886 - loss: 0.0325 - val_f1_score: 0.8374 - val_loss: 0.0405\n",
      "Epoch 68/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.8969 - loss: 0.0220 - val_f1_score: 0.8603 - val_loss: 0.0411\n",
      "Epoch 69/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.8749 - loss: 0.0321 - val_f1_score: 0.8663 - val_loss: 0.0338\n",
      "Epoch 70/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.8729 - loss: 0.0309 - val_f1_score: 0.8350 - val_loss: 0.0359\n",
      "Epoch 71/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.9014 - loss: 0.0234 - val_f1_score: 0.8525 - val_loss: 0.0415\n",
      "Epoch 72/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9004 - loss: 0.0265 - val_f1_score: 0.8726 - val_loss: 0.0293\n",
      "Epoch 73/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.8976 - loss: 0.0215 - val_f1_score: 0.8689 - val_loss: 0.0302\n",
      "Epoch 74/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9213 - loss: 0.0209 - val_f1_score: 0.8624 - val_loss: 0.0368\n",
      "Epoch 75/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9063 - loss: 0.0230 - val_f1_score: 0.8377 - val_loss: 0.0358\n",
      "Epoch 76/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9029 - loss: 0.0212 - val_f1_score: 0.8042 - val_loss: 0.0358\n",
      "Epoch 77/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - f1_score: 0.8497 - loss: 0.0329 - val_f1_score: 0.8309 - val_loss: 0.0345\n",
      "Epoch 78/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.8309 - loss: 0.0516 - val_f1_score: 0.8070 - val_loss: 0.0489\n",
      "Epoch 79/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.7655 - loss: 0.0693 - val_f1_score: 0.8023 - val_loss: 0.0479\n",
      "Epoch 80/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.8101 - loss: 0.0476 - val_f1_score: 0.8071 - val_loss: 0.0363\n",
      "Epoch 81/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.8440 - loss: 0.0410 - val_f1_score: 0.8676 - val_loss: 0.0277\n",
      "Epoch 82/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.8356 - loss: 0.0372 - val_f1_score: 0.8531 - val_loss: 0.0298\n",
      "Epoch 83/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.8614 - loss: 0.0322 - val_f1_score: 0.8591 - val_loss: 0.0339\n",
      "Epoch 84/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.8700 - loss: 0.0306 - val_f1_score: 0.8546 - val_loss: 0.0392\n",
      "Epoch 85/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.8363 - loss: 0.0535 - val_f1_score: 0.7889 - val_loss: 0.0484\n",
      "Epoch 86/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.8370 - loss: 0.0452 - val_f1_score: 0.8403 - val_loss: 0.0390\n",
      "Epoch 87/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.8702 - loss: 0.0306 - val_f1_score: 0.8402 - val_loss: 0.0386\n",
      "Epoch 88/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.8682 - loss: 0.0382 - val_f1_score: 0.8515 - val_loss: 0.0363\n",
      "Epoch 89/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.8933 - loss: 0.0263 - val_f1_score: 0.8563 - val_loss: 0.0443\n",
      "Epoch 90/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.8715 - loss: 0.0299 - val_f1_score: 0.8353 - val_loss: 0.0412\n",
      "Epoch 91/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.9027 - loss: 0.0246 - val_f1_score: 0.8851 - val_loss: 0.0319\n",
      "Epoch 92/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.9146 - loss: 0.0206 - val_f1_score: 0.8585 - val_loss: 0.0342\n",
      "Epoch 93/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - f1_score: 0.9278 - loss: 0.0170 - val_f1_score: 0.8530 - val_loss: 0.0279\n",
      "Epoch 94/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.9136 - loss: 0.0193 - val_f1_score: 0.8600 - val_loss: 0.0314\n",
      "Epoch 95/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.8936 - loss: 0.0269 - val_f1_score: 0.8715 - val_loss: 0.0338\n",
      "Epoch 96/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.9001 - loss: 0.0205 - val_f1_score: 0.8651 - val_loss: 0.0297\n",
      "Epoch 97/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.8558 - loss: 0.0411 - val_f1_score: 0.8627 - val_loss: 0.0351\n",
      "Epoch 98/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.8547 - loss: 0.0468 - val_f1_score: 0.8465 - val_loss: 0.0407\n",
      "Epoch 99/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.8736 - loss: 0.0325 - val_f1_score: 0.8248 - val_loss: 0.0344\n",
      "Epoch 100/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.8645 - loss: 0.0308 - val_f1_score: 0.8638 - val_loss: 0.0376\n",
      "Epoch 101/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9001 - loss: 0.0276 - val_f1_score: 0.8432 - val_loss: 0.0316\n",
      "Epoch 102/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.9109 - loss: 0.0243 - val_f1_score: 0.8529 - val_loss: 0.0341\n",
      "Epoch 103/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.9102 - loss: 0.0221 - val_f1_score: 0.8547 - val_loss: 0.0273\n",
      "Epoch 104/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.9146 - loss: 0.0195 - val_f1_score: 0.8848 - val_loss: 0.0307\n",
      "Epoch 105/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.8963 - loss: 0.0261 - val_f1_score: 0.8678 - val_loss: 0.0292\n",
      "Epoch 106/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.8584 - loss: 0.0319 - val_f1_score: 0.8828 - val_loss: 0.0319\n",
      "Epoch 107/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9116 - loss: 0.0228 - val_f1_score: 0.8710 - val_loss: 0.0377\n",
      "Epoch 108/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - f1_score: 0.9077 - loss: 0.0208 - val_f1_score: 0.8591 - val_loss: 0.0314\n",
      "Epoch 109/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9220 - loss: 0.0175 - val_f1_score: 0.8595 - val_loss: 0.0338\n",
      "Epoch 110/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9159 - loss: 0.0197 - val_f1_score: 0.8545 - val_loss: 0.0398\n",
      "Epoch 111/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9248 - loss: 0.0195 - val_f1_score: 0.8077 - val_loss: 0.0425\n",
      "Epoch 112/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.8297 - loss: 0.0509 - val_f1_score: 0.8528 - val_loss: 0.0439\n",
      "Epoch 113/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - f1_score: 0.8524 - loss: 0.0373 - val_f1_score: 0.7837 - val_loss: 0.0417\n",
      "Epoch 114/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.8711 - loss: 0.0292 - val_f1_score: 0.8528 - val_loss: 0.0329\n",
      "Epoch 115/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - f1_score: 0.8449 - loss: 0.0394 - val_f1_score: 0.8114 - val_loss: 0.0473\n",
      "Epoch 116/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.8747 - loss: 0.0336 - val_f1_score: 0.8269 - val_loss: 0.0345\n",
      "Epoch 117/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.8456 - loss: 0.0314 - val_f1_score: 0.7711 - val_loss: 0.0434\n",
      "Epoch 118/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - f1_score: 0.8983 - loss: 0.0181 - val_f1_score: 0.8134 - val_loss: 0.0374\n",
      "Epoch 119/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.8983 - loss: 0.0260 - val_f1_score: 0.8072 - val_loss: 0.0462\n",
      "Epoch 120/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.8972 - loss: 0.0298 - val_f1_score: 0.8708 - val_loss: 0.0313\n",
      "Epoch 121/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - f1_score: 0.9026 - loss: 0.0235 - val_f1_score: 0.8652 - val_loss: 0.0355\n",
      "Epoch 122/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9083 - loss: 0.0218 - val_f1_score: 0.8548 - val_loss: 0.0350\n",
      "Epoch 123/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - f1_score: 0.9056 - loss: 0.0226 - val_f1_score: 0.8748 - val_loss: 0.0327\n",
      "Epoch 124/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.8827 - loss: 0.0288 - val_f1_score: 0.8556 - val_loss: 0.0350\n",
      "Epoch 125/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9094 - loss: 0.0255 - val_f1_score: 0.8659 - val_loss: 0.0331\n",
      "Epoch 126/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9043 - loss: 0.0217 - val_f1_score: 0.8851 - val_loss: 0.0384\n",
      "Epoch 127/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.8904 - loss: 0.0371 - val_f1_score: 0.8443 - val_loss: 0.0298\n",
      "Epoch 128/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - f1_score: 0.9068 - loss: 0.0245 - val_f1_score: 0.8701 - val_loss: 0.0245\n",
      "Epoch 129/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9236 - loss: 0.0172 - val_f1_score: 0.8471 - val_loss: 0.0347\n",
      "Epoch 130/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9263 - loss: 0.0154 - val_f1_score: 0.8651 - val_loss: 0.0303\n",
      "Epoch 131/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9223 - loss: 0.0177 - val_f1_score: 0.8384 - val_loss: 0.0445\n",
      "Epoch 132/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.8964 - loss: 0.0208 - val_f1_score: 0.8235 - val_loss: 0.0382\n",
      "Epoch 133/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9182 - loss: 0.0167 - val_f1_score: 0.8520 - val_loss: 0.0402\n",
      "Epoch 134/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - f1_score: 0.9286 - loss: 0.0159 - val_f1_score: 0.8708 - val_loss: 0.0309\n",
      "Epoch 135/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9280 - loss: 0.0143 - val_f1_score: 0.8838 - val_loss: 0.0362\n",
      "Epoch 136/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - f1_score: 0.9122 - loss: 0.0187 - val_f1_score: 0.8662 - val_loss: 0.0350\n",
      "Epoch 137/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9261 - loss: 0.0134 - val_f1_score: 0.8655 - val_loss: 0.0391\n",
      "Epoch 138/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9116 - loss: 0.0257 - val_f1_score: 0.8715 - val_loss: 0.0432\n",
      "Epoch 139/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9225 - loss: 0.0167 - val_f1_score: 0.8517 - val_loss: 0.0462\n",
      "Epoch 140/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9142 - loss: 0.0181 - val_f1_score: 0.8961 - val_loss: 0.0340\n",
      "Epoch 141/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - f1_score: 0.9032 - loss: 0.0216 - val_f1_score: 0.8677 - val_loss: 0.0423\n",
      "Epoch 142/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - f1_score: 0.9039 - loss: 0.0207 - val_f1_score: 0.8619 - val_loss: 0.0388\n",
      "Epoch 143/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - f1_score: 0.9246 - loss: 0.0167 - val_f1_score: 0.8551 - val_loss: 0.0532\n",
      "Epoch 144/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9425 - loss: 0.0155 - val_f1_score: 0.8789 - val_loss: 0.0466\n",
      "Epoch 145/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9189 - loss: 0.0170 - val_f1_score: 0.8404 - val_loss: 0.0488\n",
      "Epoch 146/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9429 - loss: 0.0126 - val_f1_score: 0.8359 - val_loss: 0.0428\n",
      "Epoch 147/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9174 - loss: 0.0203 - val_f1_score: 0.8351 - val_loss: 0.0413\n",
      "Epoch 148/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9220 - loss: 0.0160 - val_f1_score: 0.8242 - val_loss: 0.0426\n",
      "Epoch 149/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - f1_score: 0.9327 - loss: 0.0172 - val_f1_score: 0.9123 - val_loss: 0.0278\n",
      "Epoch 150/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9073 - loss: 0.0240 - val_f1_score: 0.8796 - val_loss: 0.0321\n",
      "Epoch 151/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9230 - loss: 0.0136 - val_f1_score: 0.8253 - val_loss: 0.0391\n",
      "Epoch 152/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.8732 - loss: 0.0347 - val_f1_score: 0.8634 - val_loss: 0.0405\n",
      "Epoch 153/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - f1_score: 0.8989 - loss: 0.0235 - val_f1_score: 0.8564 - val_loss: 0.0401\n",
      "Epoch 154/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9178 - loss: 0.0160 - val_f1_score: 0.8682 - val_loss: 0.0399\n",
      "Epoch 155/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9160 - loss: 0.0208 - val_f1_score: 0.8905 - val_loss: 0.0245\n",
      "Epoch 156/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9061 - loss: 0.0260 - val_f1_score: 0.8886 - val_loss: 0.0299\n",
      "Epoch 157/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9226 - loss: 0.0211 - val_f1_score: 0.8642 - val_loss: 0.0347\n",
      "Epoch 158/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9367 - loss: 0.0159 - val_f1_score: 0.8830 - val_loss: 0.0271\n",
      "Epoch 159/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9376 - loss: 0.0127 - val_f1_score: 0.8846 - val_loss: 0.0245\n",
      "Epoch 160/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9001 - loss: 0.0196 - val_f1_score: 0.8454 - val_loss: 0.0303\n",
      "Epoch 161/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9438 - loss: 0.0154 - val_f1_score: 0.8554 - val_loss: 0.0303\n",
      "Epoch 162/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9302 - loss: 0.0151 - val_f1_score: 0.8849 - val_loss: 0.0333\n",
      "Epoch 163/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - f1_score: 0.9131 - loss: 0.0209 - val_f1_score: 0.8441 - val_loss: 0.0333\n",
      "Epoch 164/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9331 - loss: 0.0165 - val_f1_score: 0.8621 - val_loss: 0.0255\n",
      "Epoch 165/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.8983 - loss: 0.0200 - val_f1_score: 0.8426 - val_loss: 0.0294\n",
      "Epoch 166/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - f1_score: 0.9060 - loss: 0.0167 - val_f1_score: 0.8319 - val_loss: 0.0377\n",
      "Epoch 167/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9402 - loss: 0.0123 - val_f1_score: 0.8517 - val_loss: 0.0339\n",
      "Epoch 168/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9368 - loss: 0.0156 - val_f1_score: 0.8592 - val_loss: 0.0430\n",
      "Epoch 169/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9342 - loss: 0.0148 - val_f1_score: 0.8232 - val_loss: 0.0444\n",
      "Epoch 170/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9296 - loss: 0.0162 - val_f1_score: 0.8557 - val_loss: 0.0342\n",
      "Epoch 171/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9485 - loss: 0.0101 - val_f1_score: 0.8745 - val_loss: 0.0402\n",
      "Epoch 172/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - f1_score: 0.9520 - loss: 0.0104 - val_f1_score: 0.8536 - val_loss: 0.0378\n",
      "Epoch 173/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9333 - loss: 0.0149 - val_f1_score: 0.8688 - val_loss: 0.0315\n",
      "Epoch 174/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9412 - loss: 0.0149 - val_f1_score: 0.8814 - val_loss: 0.0358\n",
      "Epoch 175/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - f1_score: 0.9539 - loss: 0.0117 - val_f1_score: 0.8778 - val_loss: 0.0358\n",
      "Epoch 176/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9162 - loss: 0.0228 - val_f1_score: 0.8436 - val_loss: 0.0444\n",
      "Epoch 177/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9292 - loss: 0.0188 - val_f1_score: 0.8324 - val_loss: 0.0520\n",
      "Epoch 178/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9517 - loss: 0.0110 - val_f1_score: 0.8719 - val_loss: 0.0328\n",
      "Epoch 179/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9323 - loss: 0.0139 - val_f1_score: 0.8564 - val_loss: 0.0344\n",
      "Epoch 180/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - f1_score: 0.9233 - loss: 0.0210 - val_f1_score: 0.8894 - val_loss: 0.0308\n",
      "Epoch 181/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - f1_score: 0.9488 - loss: 0.0134 - val_f1_score: 0.9023 - val_loss: 0.0273\n",
      "Epoch 182/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9410 - loss: 0.0139 - val_f1_score: 0.8765 - val_loss: 0.0361\n",
      "Epoch 183/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9469 - loss: 0.0126 - val_f1_score: 0.8508 - val_loss: 0.0419\n",
      "Epoch 184/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9395 - loss: 0.0160 - val_f1_score: 0.9141 - val_loss: 0.0280\n",
      "Epoch 185/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9445 - loss: 0.0124 - val_f1_score: 0.8664 - val_loss: 0.0356\n",
      "Epoch 186/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - f1_score: 0.9447 - loss: 0.0129 - val_f1_score: 0.8650 - val_loss: 0.0376\n",
      "Epoch 187/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.9465 - loss: 0.0176 - val_f1_score: 0.8430 - val_loss: 0.0462\n",
      "Epoch 188/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - f1_score: 0.9442 - loss: 0.0112 - val_f1_score: 0.8796 - val_loss: 0.0422\n",
      "Epoch 189/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - f1_score: 0.8648 - loss: 0.0514 - val_f1_score: 0.8549 - val_loss: 0.0490\n",
      "Epoch 190/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - f1_score: 0.8757 - loss: 0.0312 - val_f1_score: 0.9000 - val_loss: 0.0285\n",
      "Epoch 191/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.8940 - loss: 0.0335 - val_f1_score: 0.8628 - val_loss: 0.0443\n",
      "Epoch 192/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - f1_score: 0.8813 - loss: 0.0304 - val_f1_score: 0.8146 - val_loss: 0.0410\n",
      "Epoch 193/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9178 - loss: 0.0212 - val_f1_score: 0.8697 - val_loss: 0.0342\n",
      "Epoch 194/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9217 - loss: 0.0199 - val_f1_score: 0.8526 - val_loss: 0.0425\n",
      "Epoch 195/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9061 - loss: 0.0189 - val_f1_score: 0.8321 - val_loss: 0.0442\n",
      "Epoch 196/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9253 - loss: 0.0170 - val_f1_score: 0.8496 - val_loss: 0.0502\n",
      "Epoch 197/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - f1_score: 0.8981 - loss: 0.0215 - val_f1_score: 0.8700 - val_loss: 0.0487\n",
      "Epoch 198/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9376 - loss: 0.0174 - val_f1_score: 0.8626 - val_loss: 0.0434\n",
      "Epoch 199/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9085 - loss: 0.0258 - val_f1_score: 0.8343 - val_loss: 0.0527\n",
      "Epoch 200/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9141 - loss: 0.0159 - val_f1_score: 0.8629 - val_loss: 0.0480\n",
      "Restoring model weights from the end of the best epoch: 184.\n"
     ]
    }
   ],
   "source": [
    "model2.compile(optimizer='adam', metrics=[F1Score(average='macro', name='f1_score')], loss='categorical_focal_crossentropy')\n",
    "history2 = model2.fit(X_train, y_train, epochs=200, validation_split=0.1, callbacks=[stop_early(patience=50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "pose_jumping_jacks_down       0.83      0.91      0.87        47\n",
      "  pose_jumping_jacks_up       0.92      0.73      0.81        45\n",
      "           pose_no_pose       0.99      1.00      1.00       180\n",
      "      pose_pullups_down       0.81      0.87      0.84        39\n",
      "        pose_pullups_up       0.66      0.79      0.72        34\n",
      "      pose_pushups_down       0.79      0.88      0.83        25\n",
      "        pose_pushups_up       0.88      0.83      0.86        36\n",
      "        pose_situp_down       0.91      0.84      0.88        25\n",
      "          pose_situp_up       0.88      0.84      0.86        25\n",
      "       pose_squats_down       0.96      0.84      0.90        32\n",
      "         pose_squats_up       0.68      0.66      0.67        35\n",
      "\n",
      "               accuracy                           0.88       523\n",
      "              macro avg       0.85      0.84      0.84       523\n",
      "           weighted avg       0.89      0.88      0.88       523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=np.argmax(y_test, axis=1),\n",
    "                            y_pred=np.argmax(model2.predict(X_test), axis=1),\n",
    "                            target_names=y.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(model2.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x72e1557f1dd0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vf1_arr = history2.history[\"val_f1_score\"]\n",
    "f1_arr = history2.history[\"f1_score\"]\n",
    "plt.plot(range(len(vf1_arr)),vf1_arr)\n",
    "plt.plot(range(len(f1_arr)),f1_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_res = np.argmax(model2.predict(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "df_res = pd.DataFrame(np.argmax(model2.predict(X_test), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = df_res.map(lambda x:y.columns.values[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pose_no_pose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pose_no_pose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pose_situp_up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pose_squats_up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pose_jumping_jacks_down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>pose_pullups_up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>pose_situp_down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>pose_no_pose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>pose_pushups_down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>pose_situp_down</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>523 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0\n",
       "0               pose_no_pose\n",
       "1               pose_no_pose\n",
       "2              pose_situp_up\n",
       "3             pose_squats_up\n",
       "4    pose_jumping_jacks_down\n",
       "..                       ...\n",
       "518          pose_pullups_up\n",
       "519          pose_situp_down\n",
       "520             pose_no_pose\n",
       "521        pose_pushups_down\n",
       "522          pose_situp_down\n",
       "\n",
       "[523 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 14:48:29.337366: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-03 14:48:29.337405: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-03 14:48:29.337414: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-03 14:48:29.544196: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2951 files belonging to 4 classes.\n",
      "Using 2361 files for training.\n",
      "Using 590 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 14:48:34.722475: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-03 14:48:35.652047: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-03 14:48:35.652288: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-03 14:48:35.655115: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-03 14:48:35.655386: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-03 14:48:35.655546: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-03 14:48:35.743582: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-03 14:48:35.744550: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-03 14:48:35.744728: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-03 14:48:35.744851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2203 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2025-04-03 14:48:36.375021: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 128, 16)      448       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 32)      4640      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 128, 128, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 64, 64, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 64, 64, 64)        256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 64, 64, 16)        9232      \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 64, 64, 32)        4640      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 32, 32, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 32, 32, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 32, 32, 16)        9232      \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 32, 32, 32)        4640      \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 16, 16, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 16, 16, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 8, 8, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 8, 8, 64)          256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 8, 8, 16)          9232      \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 8, 8, 32)          4640      \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 8, 8, 64)          18496     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 4, 4, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 4, 4, 64)          256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 4, 4, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 187828 (733.70 KB)\n",
      "Trainable params: 187188 (731.20 KB)\n",
      "Non-trainable params: 640 (2.50 KB)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 14:48:40.253798: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2025-04-03 14:48:41.745599: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2025-04-03 14:48:42.179298: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-04-03 14:48:44.814988: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5cb809d12500 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-04-03 14:48:44.815015: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2025-04-03 14:48:44.850479: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-04-03 14:48:45.042785: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2025-04-03 14:48:48.737387: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-04-03 14:48:48.823168: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-04-03 14:48:48.863170: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.65GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-04-03 14:48:48.863278: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.65GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/74 [===========>..................] - ETA: 7s - loss: 0.9902 - accuracy: 0.6221"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 14:48:57.851397: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.81GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-04-03 14:48:57.922004: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.81GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 30s 237ms/step - loss: 0.6357 - accuracy: 0.7607 - val_loss: 1.3149 - val_accuracy: 0.4559\n",
      "Epoch 2/5\n",
      "74/74 [==============================] - 13s 176ms/step - loss: 0.1752 - accuracy: 0.9416 - val_loss: 1.3731 - val_accuracy: 0.4356\n",
      "Epoch 3/5\n",
      "74/74 [==============================] - 13s 173ms/step - loss: 0.0807 - accuracy: 0.9776 - val_loss: 1.6006 - val_accuracy: 0.4254\n",
      "Epoch 4/5\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 0.0565 - accuracy: 0.9843 - val_loss: 0.1819 - val_accuracy: 0.9390\n",
      "Epoch 5/5\n",
      "74/74 [==============================] - 13s 174ms/step - loss: 0.0357 - accuracy: 0.9890 - val_loss: 0.2046 - val_accuracy: 0.9220\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dense, Dropout, BatchNormalization, Resizing, Flatten\n",
    "from keras.metrics import F1Score\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def stop_early(patience=10, start=10):\n",
    "    # Early stopping to halt training when validation performance stops improving\n",
    "    return EarlyStopping(\n",
    "        monitor='val_accuracy',  # Monitor F1 score on validation data\n",
    "        patience=patience,  # Number of epochs to wait for improvement\n",
    "        verbose=1,\n",
    "        mode='max',  # Stop when F1 score stops increasing\n",
    "        restore_best_weights=True,  # Restore best weights\n",
    "        start_from_epoch=start  # Epoch to start monitoring\n",
    "    )\n",
    "\n",
    "\n",
    "train_ds, valid_ds = image_dataset_from_directory(\n",
    "    'images',\n",
    "    image_size = (128,128),\n",
    "    seed = 38,\n",
    "    subset = 'both',\n",
    "    validation_split = 0.2\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "\n",
    "with open(\"classes.csv\", \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(class_names)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "valid_ds = valid_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(128,128,3,)),\n",
    "    Conv2D(16, kernel_size= 3, activation='relu', padding='same'),\n",
    "    Conv2D(32, kernel_size= 3, activation='relu', padding='same'),\n",
    "    Conv2D(64, kernel_size= 3, activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Conv2D(16, kernel_size= 3, activation='relu', padding='same'),\n",
    "    Conv2D(32, kernel_size= 3, activation='relu', padding='same'),\n",
    "    Conv2D(64, kernel_size= 3, activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Conv2D(16, kernel_size= 3, activation='relu', padding='same'),\n",
    "    Conv2D(32, kernel_size= 3, activation='relu', padding='same'),\n",
    "    Conv2D(64, kernel_size= 3, activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=2),    \n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Conv2D(16, kernel_size= 3, activation='relu', padding='same'),\n",
    "    Conv2D(32, kernel_size= 3, activation='relu', padding='same'),\n",
    "    Conv2D(64, kernel_size= 3, activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=5,\n",
    "    validation_data=valid_ds\n",
    ")\n",
    "\n",
    "model.save('cnn.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "push",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
