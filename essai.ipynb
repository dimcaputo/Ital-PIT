{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_nose</th>\n",
       "      <th>y_nose</th>\n",
       "      <th>z_nose</th>\n",
       "      <th>x_left_eye_inner</th>\n",
       "      <th>y_left_eye_inner</th>\n",
       "      <th>z_left_eye_inner</th>\n",
       "      <th>x_left_eye</th>\n",
       "      <th>y_left_eye</th>\n",
       "      <th>z_left_eye</th>\n",
       "      <th>x_left_eye_outer</th>\n",
       "      <th>...</th>\n",
       "      <th>z_left_heel</th>\n",
       "      <th>x_right_heel</th>\n",
       "      <th>y_right_heel</th>\n",
       "      <th>z_right_heel</th>\n",
       "      <th>x_left_foot_index</th>\n",
       "      <th>y_left_foot_index</th>\n",
       "      <th>z_left_foot_index</th>\n",
       "      <th>x_right_foot_index</th>\n",
       "      <th>y_right_foot_index</th>\n",
       "      <th>z_right_foot_index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pose_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.889507</td>\n",
       "      <td>-57.637520</td>\n",
       "      <td>-45.019750</td>\n",
       "      <td>-4.656085</td>\n",
       "      <td>-62.832863</td>\n",
       "      <td>-44.571823</td>\n",
       "      <td>-3.302626</td>\n",
       "      <td>-63.386856</td>\n",
       "      <td>-44.567863</td>\n",
       "      <td>-2.032406</td>\n",
       "      <td>...</td>\n",
       "      <td>56.852562</td>\n",
       "      <td>-0.842025</td>\n",
       "      <td>35.037060</td>\n",
       "      <td>50.565020</td>\n",
       "      <td>5.842190</td>\n",
       "      <td>45.971020</td>\n",
       "      <td>50.263714</td>\n",
       "      <td>0.092779</td>\n",
       "      <td>45.842150</td>\n",
       "      <td>41.427795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.255504</td>\n",
       "      <td>-62.935925</td>\n",
       "      <td>-128.907500</td>\n",
       "      <td>-2.977403</td>\n",
       "      <td>-67.035990</td>\n",
       "      <td>-124.258545</td>\n",
       "      <td>-2.215265</td>\n",
       "      <td>-67.198250</td>\n",
       "      <td>-124.263240</td>\n",
       "      <td>-1.494903</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.129170</td>\n",
       "      <td>-1.298891</td>\n",
       "      <td>54.733307</td>\n",
       "      <td>-6.886051</td>\n",
       "      <td>3.980098</td>\n",
       "      <td>65.370830</td>\n",
       "      <td>-49.023930</td>\n",
       "      <td>-5.090634</td>\n",
       "      <td>65.641780</td>\n",
       "      <td>-42.878056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.878917</td>\n",
       "      <td>-61.709988</td>\n",
       "      <td>-137.453340</td>\n",
       "      <td>-1.619050</td>\n",
       "      <td>-65.693750</td>\n",
       "      <td>-132.181660</td>\n",
       "      <td>-0.785822</td>\n",
       "      <td>-65.814340</td>\n",
       "      <td>-132.184070</td>\n",
       "      <td>-0.019743</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.904400</td>\n",
       "      <td>-2.119770</td>\n",
       "      <td>51.265694</td>\n",
       "      <td>-15.554097</td>\n",
       "      <td>1.994894</td>\n",
       "      <td>62.725025</td>\n",
       "      <td>-57.717957</td>\n",
       "      <td>-4.452602</td>\n",
       "      <td>62.494457</td>\n",
       "      <td>-53.804527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.242575</td>\n",
       "      <td>-60.371220</td>\n",
       "      <td>-135.094830</td>\n",
       "      <td>-3.118133</td>\n",
       "      <td>-64.416000</td>\n",
       "      <td>-129.995930</td>\n",
       "      <td>-2.369744</td>\n",
       "      <td>-64.603290</td>\n",
       "      <td>-130.003400</td>\n",
       "      <td>-1.753780</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.855729</td>\n",
       "      <td>-1.485475</td>\n",
       "      <td>59.729427</td>\n",
       "      <td>1.433403</td>\n",
       "      <td>1.950102</td>\n",
       "      <td>68.187256</td>\n",
       "      <td>-42.989098</td>\n",
       "      <td>-4.573338</td>\n",
       "      <td>68.144350</td>\n",
       "      <td>-34.117043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.805543</td>\n",
       "      <td>-56.178570</td>\n",
       "      <td>-41.124413</td>\n",
       "      <td>-0.055174</td>\n",
       "      <td>-58.501305</td>\n",
       "      <td>-37.938560</td>\n",
       "      <td>0.456936</td>\n",
       "      <td>-58.473960</td>\n",
       "      <td>-37.954430</td>\n",
       "      <td>0.969290</td>\n",
       "      <td>...</td>\n",
       "      <td>47.124107</td>\n",
       "      <td>-2.455719</td>\n",
       "      <td>52.861732</td>\n",
       "      <td>45.936783</td>\n",
       "      <td>2.699764</td>\n",
       "      <td>57.254112</td>\n",
       "      <td>27.531416</td>\n",
       "      <td>-2.288348</td>\n",
       "      <td>57.803005</td>\n",
       "      <td>26.288315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x_nose     y_nose      z_nose  x_left_eye_inner  y_left_eye_inner  \\\n",
       "pose_id                                                                        \n",
       "0       -5.889507 -57.637520  -45.019750         -4.656085        -62.832863   \n",
       "1       -4.255504 -62.935925 -128.907500         -2.977403        -67.035990   \n",
       "2       -2.878917 -61.709988 -137.453340         -1.619050        -65.693750   \n",
       "3       -4.242575 -60.371220 -135.094830         -3.118133        -64.416000   \n",
       "4       -0.805543 -56.178570  -41.124413         -0.055174        -58.501305   \n",
       "\n",
       "         z_left_eye_inner  x_left_eye  y_left_eye  z_left_eye  \\\n",
       "pose_id                                                         \n",
       "0              -44.571823   -3.302626  -63.386856  -44.567863   \n",
       "1             -124.258545   -2.215265  -67.198250 -124.263240   \n",
       "2             -132.181660   -0.785822  -65.814340 -132.184070   \n",
       "3             -129.995930   -2.369744  -64.603290 -130.003400   \n",
       "4              -37.938560    0.456936  -58.473960  -37.954430   \n",
       "\n",
       "         x_left_eye_outer  ...  z_left_heel  x_right_heel  y_right_heel  \\\n",
       "pose_id                    ...                                            \n",
       "0               -2.032406  ...    56.852562     -0.842025     35.037060   \n",
       "1               -1.494903  ...   -14.129170     -1.298891     54.733307   \n",
       "2               -0.019743  ...   -19.904400     -2.119770     51.265694   \n",
       "3               -1.753780  ...    -6.855729     -1.485475     59.729427   \n",
       "4                0.969290  ...    47.124107     -2.455719     52.861732   \n",
       "\n",
       "         z_right_heel  x_left_foot_index  y_left_foot_index  \\\n",
       "pose_id                                                       \n",
       "0           50.565020           5.842190          45.971020   \n",
       "1           -6.886051           3.980098          65.370830   \n",
       "2          -15.554097           1.994894          62.725025   \n",
       "3            1.433403           1.950102          68.187256   \n",
       "4           45.936783           2.699764          57.254112   \n",
       "\n",
       "         z_left_foot_index  x_right_foot_index  y_right_foot_index  \\\n",
       "pose_id                                                              \n",
       "0                50.263714            0.092779           45.842150   \n",
       "1               -49.023930           -5.090634           65.641780   \n",
       "2               -57.717957           -4.452602           62.494457   \n",
       "3               -42.989098           -4.573338           68.144350   \n",
       "4                27.531416           -2.288348           57.803005   \n",
       "\n",
       "         z_right_foot_index  \n",
       "pose_id                      \n",
       "0                 41.427795  \n",
       "1                -42.878056  \n",
       "2                -53.804527  \n",
       "3                -34.117043  \n",
       "4                 26.288315  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features = pd.read_csv(filepath_or_buffer='training_data/landmarks.csv',\n",
    "                 index_col='pose_id')\n",
    "\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pose</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pose_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jumping_jacks_down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jumping_jacks_down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jumping_jacks_down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jumping_jacks_down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jumping_jacks_down</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       pose\n",
       "pose_id                    \n",
       "0        jumping_jacks_down\n",
       "1        jumping_jacks_down\n",
       "2        jumping_jacks_down\n",
       "3        jumping_jacks_down\n",
       "4        jumping_jacks_down"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = pd.read_csv(filepath_or_buffer='training_data/labels.csv',\n",
    "                        index_col='pose_id')\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_features.values\n",
    "y = pd.get_dummies(df_labels, dtype=int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=38, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m6,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,530</span> (76.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,530\u001b[0m (76.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,530</span> (76.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,530\u001b[0m (76.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(99,)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_early(check, patience=10):\n",
    "    earlystopping=EarlyStopping(patience=patience,\n",
    "                                restore_best_weights=True,\n",
    "                                monitor=check,\n",
    "                                mode='max',\n",
    "                                start_from_epoch=50)\n",
    "    return earlystopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - f1_score: 0.1945 - loss: 0.4083 - val_f1_score: 0.4526 - val_loss: 0.2752\n",
      "Epoch 2/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.5743 - loss: 0.2107 - val_f1_score: 0.6637 - val_loss: 0.1758\n",
      "Epoch 3/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.6888 - loss: 0.1170 - val_f1_score: 0.7599 - val_loss: 0.1579\n",
      "Epoch 4/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.7387 - loss: 0.0857 - val_f1_score: 0.7427 - val_loss: 0.1357\n",
      "Epoch 5/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8267 - loss: 0.0647 - val_f1_score: 0.7317 - val_loss: 0.1379\n",
      "Epoch 6/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.7963 - loss: 0.0614 - val_f1_score: 0.7012 - val_loss: 0.1433\n",
      "Epoch 7/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.7498 - loss: 0.0579 - val_f1_score: 0.7465 - val_loss: 0.1351\n",
      "Epoch 8/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8284 - loss: 0.0469 - val_f1_score: 0.7864 - val_loss: 0.1369\n",
      "Epoch 9/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8592 - loss: 0.0445 - val_f1_score: 0.7851 - val_loss: 0.1385\n",
      "Epoch 10/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8876 - loss: 0.0316 - val_f1_score: 0.7847 - val_loss: 0.1429\n",
      "Epoch 11/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9012 - loss: 0.0303 - val_f1_score: 0.7946 - val_loss: 0.1519\n",
      "Epoch 12/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8469 - loss: 0.0307 - val_f1_score: 0.8181 - val_loss: 0.1387\n",
      "Epoch 13/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8591 - loss: 0.0292 - val_f1_score: 0.8241 - val_loss: 0.1462\n",
      "Epoch 14/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.7869 - loss: 0.0255 - val_f1_score: 0.7837 - val_loss: 0.1693\n",
      "Epoch 15/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8398 - loss: 0.0242 - val_f1_score: 0.7770 - val_loss: 0.1532\n",
      "Epoch 16/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8054 - loss: 0.0260 - val_f1_score: 0.7959 - val_loss: 0.1580\n",
      "Epoch 17/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9166 - loss: 0.0220 - val_f1_score: 0.8145 - val_loss: 0.1408\n",
      "Epoch 18/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8310 - loss: 0.0186 - val_f1_score: 0.8110 - val_loss: 0.1501\n",
      "Epoch 19/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8579 - loss: 0.0190 - val_f1_score: 0.8026 - val_loss: 0.1485\n",
      "Epoch 20/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8578 - loss: 0.0174 - val_f1_score: 0.8297 - val_loss: 0.1635\n",
      "Epoch 21/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8361 - loss: 0.0141 - val_f1_score: 0.8056 - val_loss: 0.1544\n",
      "Epoch 22/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.7586 - loss: 0.0127 - val_f1_score: 0.8396 - val_loss: 0.1600\n",
      "Epoch 23/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.7122 - loss: 0.0170 - val_f1_score: 0.8117 - val_loss: 0.1710\n",
      "Epoch 24/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.7311 - loss: 0.0129 - val_f1_score: 0.8108 - val_loss: 0.1625\n",
      "Epoch 25/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9716 - loss: 0.0090 - val_f1_score: 0.8115 - val_loss: 0.1793\n",
      "Epoch 26/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9557 - loss: 0.0111 - val_f1_score: 0.8092 - val_loss: 0.1806\n",
      "Epoch 27/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9269 - loss: 0.0121 - val_f1_score: 0.8075 - val_loss: 0.1688\n",
      "Epoch 28/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9252 - loss: 0.0105 - val_f1_score: 0.8330 - val_loss: 0.1607\n",
      "Epoch 29/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8772 - loss: 0.0079 - val_f1_score: 0.7737 - val_loss: 0.1802\n",
      "Epoch 30/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8978 - loss: 0.0080 - val_f1_score: 0.8189 - val_loss: 0.1820\n",
      "Epoch 31/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.6559 - loss: 0.0082 - val_f1_score: 0.8261 - val_loss: 0.1782\n",
      "Epoch 32/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9113 - loss: 0.0076 - val_f1_score: 0.8124 - val_loss: 0.1674\n",
      "Epoch 33/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8805 - loss: 0.0083 - val_f1_score: 0.8272 - val_loss: 0.1764\n",
      "Epoch 34/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9438 - loss: 0.0049 - val_f1_score: 0.8011 - val_loss: 0.1746\n",
      "Epoch 35/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.7974 - loss: 0.0077 - val_f1_score: 0.8143 - val_loss: 0.1681\n",
      "Epoch 36/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.7483 - loss: 0.0085 - val_f1_score: 0.8535 - val_loss: 0.1590\n",
      "Epoch 37/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.7778 - loss: 0.0067 - val_f1_score: 0.8373 - val_loss: 0.1878\n",
      "Epoch 38/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8006 - loss: 0.0047 - val_f1_score: 0.8357 - val_loss: 0.1811\n",
      "Epoch 39/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8925 - loss: 0.0044 - val_f1_score: 0.8262 - val_loss: 0.1805\n",
      "Epoch 40/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - f1_score: 0.9290 - loss: 0.0032 - val_f1_score: 0.8110 - val_loss: 0.1764\n",
      "Epoch 41/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8897 - loss: 0.0047 - val_f1_score: 0.8238 - val_loss: 0.1830\n",
      "Epoch 42/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8959 - loss: 0.0031 - val_f1_score: 0.8053 - val_loss: 0.1942\n",
      "Epoch 43/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8910 - loss: 0.0048 - val_f1_score: 0.7971 - val_loss: 0.1874\n",
      "Epoch 44/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9024 - loss: 0.0098 - val_f1_score: 0.7685 - val_loss: 0.2320\n",
      "Epoch 45/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - f1_score: 0.7483 - loss: 0.0192 - val_f1_score: 0.7935 - val_loss: 0.2117\n",
      "Epoch 46/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8795 - loss: 0.0088 - val_f1_score: 0.8520 - val_loss: 0.1928\n",
      "Epoch 47/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8314 - loss: 0.0081 - val_f1_score: 0.8176 - val_loss: 0.1552\n",
      "Epoch 48/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9224 - loss: 0.0125 - val_f1_score: 0.8056 - val_loss: 0.1521\n",
      "Epoch 49/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.7289 - loss: 0.0071 - val_f1_score: 0.8395 - val_loss: 0.1396\n",
      "Epoch 50/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9461 - loss: 0.0044 - val_f1_score: 0.7995 - val_loss: 0.1630\n",
      "Epoch 51/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8210 - loss: 0.0038 - val_f1_score: 0.8046 - val_loss: 0.1591\n",
      "Epoch 52/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8735 - loss: 0.0024 - val_f1_score: 0.8490 - val_loss: 0.1546\n",
      "Epoch 53/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8548 - loss: 0.0018 - val_f1_score: 0.8440 - val_loss: 0.1576\n",
      "Epoch 54/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9890 - loss: 0.0024 - val_f1_score: 0.8424 - val_loss: 0.1578\n",
      "Epoch 55/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9554 - loss: 0.0024 - val_f1_score: 0.8512 - val_loss: 0.1632\n",
      "Epoch 56/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9668 - loss: 0.0016 - val_f1_score: 0.8210 - val_loss: 0.1808\n",
      "Epoch 57/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9890 - loss: 0.0019 - val_f1_score: 0.8595 - val_loss: 0.1636\n",
      "Epoch 58/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8480 - loss: 0.0020 - val_f1_score: 0.8352 - val_loss: 0.1628\n",
      "Epoch 59/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9304 - loss: 0.0019 - val_f1_score: 0.8134 - val_loss: 0.1715\n",
      "Epoch 60/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.7130 - loss: 0.0011 - val_f1_score: 0.8399 - val_loss: 0.1711\n",
      "Epoch 61/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9034 - loss: 0.0014 - val_f1_score: 0.8532 - val_loss: 0.1601\n",
      "Epoch 62/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9647 - loss: 0.0023 - val_f1_score: 0.8354 - val_loss: 0.1683\n",
      "Epoch 63/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8794 - loss: 0.0033 - val_f1_score: 0.8512 - val_loss: 0.1726\n",
      "Epoch 64/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9308 - loss: 0.0017 - val_f1_score: 0.8490 - val_loss: 0.1767\n",
      "Epoch 65/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8766 - loss: 0.0012 - val_f1_score: 0.8314 - val_loss: 0.1782\n",
      "Epoch 66/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9007 - loss: 0.0012 - val_f1_score: 0.8570 - val_loss: 0.1815\n",
      "Epoch 67/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9019 - loss: 0.0015 - val_f1_score: 0.8491 - val_loss: 0.1829\n",
      "Epoch 68/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9979 - loss: 9.9307e-04 - val_f1_score: 0.8395 - val_loss: 0.1829\n",
      "Epoch 69/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8983 - loss: 0.0028 - val_f1_score: 0.8258 - val_loss: 0.1736\n",
      "Epoch 70/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9509 - loss: 0.0031 - val_f1_score: 0.8126 - val_loss: 0.2020\n",
      "Epoch 71/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9038 - loss: 0.0015 - val_f1_score: 0.8532 - val_loss: 0.1786\n",
      "Epoch 72/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8780 - loss: 0.0013 - val_f1_score: 0.8502 - val_loss: 0.2000\n",
      "Epoch 73/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9383 - loss: 0.0018 - val_f1_score: 0.8300 - val_loss: 0.2072\n",
      "Epoch 74/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8138 - loss: 0.0063 - val_f1_score: 0.7931 - val_loss: 0.2155\n",
      "Epoch 75/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9320 - loss: 0.0098 - val_f1_score: 0.8187 - val_loss: 0.1786\n",
      "Epoch 76/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.6318 - loss: 0.0083 - val_f1_score: 0.8078 - val_loss: 0.1961\n",
      "Epoch 77/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - f1_score: 0.8847 - loss: 0.0048 - val_f1_score: 0.8311 - val_loss: 0.1843\n",
      "Epoch 78/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - f1_score: 0.9296 - loss: 0.0036 - val_f1_score: 0.8547 - val_loss: 0.1844\n",
      "Epoch 79/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9310 - loss: 0.0018 - val_f1_score: 0.8436 - val_loss: 0.1899\n",
      "Epoch 80/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9602 - loss: 0.0020 - val_f1_score: 0.8612 - val_loss: 0.2046\n",
      "Epoch 81/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8559 - loss: 8.8466e-04 - val_f1_score: 0.8612 - val_loss: 0.2043\n",
      "Epoch 82/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9641 - loss: 9.5381e-04 - val_f1_score: 0.8612 - val_loss: 0.1978\n",
      "Epoch 83/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9677 - loss: 5.6895e-04 - val_f1_score: 0.8612 - val_loss: 0.2015\n",
      "Epoch 84/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9091 - loss: 4.2087e-04 - val_f1_score: 0.8612 - val_loss: 0.1988\n",
      "Epoch 85/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8543 - loss: 4.6049e-04 - val_f1_score: 0.8612 - val_loss: 0.2016\n",
      "Epoch 86/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.7662 - loss: 9.5130e-04 - val_f1_score: 0.8612 - val_loss: 0.2026\n",
      "Epoch 87/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8280 - loss: 3.3208e-04 - val_f1_score: 0.8612 - val_loss: 0.1994\n",
      "Epoch 88/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9369 - loss: 3.6903e-04 - val_f1_score: 0.8612 - val_loss: 0.2046\n",
      "Epoch 89/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8530 - loss: 5.2407e-04 - val_f1_score: 0.8612 - val_loss: 0.2002\n",
      "Epoch 90/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8108 - loss: 4.2523e-04 - val_f1_score: 0.8612 - val_loss: 0.2020\n",
      "Epoch 91/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.7895 - loss: 3.1205e-04 - val_f1_score: 0.8612 - val_loss: 0.2016\n",
      "Epoch 92/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8824 - loss: 2.6414e-04 - val_f1_score: 0.8612 - val_loss: 0.2044\n",
      "Epoch 93/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8333 - loss: 2.2225e-04 - val_f1_score: 0.8612 - val_loss: 0.2037\n",
      "Epoch 94/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9061 - loss: 2.3957e-04 - val_f1_score: 0.8612 - val_loss: 0.2028\n",
      "Epoch 95/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.9355 - loss: 3.3334e-04 - val_f1_score: 0.8612 - val_loss: 0.2060\n",
      "Epoch 96/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.6439 - loss: 7.7939e-04 - val_f1_score: 0.8612 - val_loss: 0.2049\n",
      "Epoch 97/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8101 - loss: 3.3453e-04 - val_f1_score: 0.8612 - val_loss: 0.2062\n",
      "Epoch 98/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 1.0000 - loss: 2.1802e-04 - val_f1_score: 0.8612 - val_loss: 0.2061\n",
      "Epoch 99/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.8300 - loss: 1.9692e-04 - val_f1_score: 0.8612 - val_loss: 0.2077\n",
      "Epoch 100/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - f1_score: 0.9663 - loss: 3.6621e-04 - val_f1_score: 0.8612 - val_loss: 0.2056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7c860e6e36e0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', metrics=['f1_score'], loss='categorical_focal_crossentropy')\n",
    "model.fit(X_train, y_train, epochs=100, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (50,) and (100, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m50\u001b[39m),model\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_score\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/KTF/lib/python3.12/site-packages/matplotlib/pyplot.py:3829\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3821\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   3822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3827\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3828\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[0;32m-> 3829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[1;32m   3830\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m   3831\u001b[0m         scalex\u001b[38;5;241m=\u001b[39mscalex,\n\u001b[1;32m   3832\u001b[0m         scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[1;32m   3833\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[1;32m   3834\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3835\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/KTF/lib/python3.12/site-packages/matplotlib/axes/_axes.py:1777\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1535\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1536\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1776\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1777\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1779\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/anaconda3/envs/KTF/lib/python3.12/site-packages/matplotlib/axes/_base.py:297\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    296\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_plot_args(\n\u001b[1;32m    298\u001b[0m     axes, this, kwargs, ambiguous_fmt_datakey\u001b[38;5;241m=\u001b[39mambiguous_fmt_datakey,\n\u001b[1;32m    299\u001b[0m     return_kwargs\u001b[38;5;241m=\u001b[39mreturn_kwargs\n\u001b[1;32m    300\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/KTF/lib/python3.12/site-packages/matplotlib/axes/_base.py:494\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    491\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    495\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    498\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (50,) and (100, 10)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAGiCAYAAADA0E3hAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHLtJREFUeJzt3W9sleX9+PFPaWmrbq0RtBZBBKcTJepoA6OsGp3WoNGQbJHFRdRpYrM5hE6njEWGMWl00X11Cm4KGhN0REXng87RBxtWcX9gxRghcRFmQVtJMbaoWxlw/x4Y+lvX4ji1f7ja1yu5H5zL+z7nOrms5+19nz95WZZlAQCQgDHDPQEAgCMlXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBk5Bwur7zySlx55ZUxYcKEyMvLixdffPF/HrNhw4aoqKiI4uLimDp1ajz66KP9mSsAMMrlHC6ffPJJnHfeefHwww8f0f47duyIyy+/PKqrq6O5uTl+8pOfxMKFC+P555/PebIAwOiW90V+ZDEvLy9eeOGFmDdv3mH3ueOOO+Kll16Kbdu2dY/V1tbGG2+8Ea+//np/HxoAGIUKBvsBXn/99aipqekxdtlll8WqVavi3//+d4wdO7bXMV1dXdHV1dV9++DBg/Hhhx/GuHHjIi8vb7CnDAAMgCzLYu/evTFhwoQYM2Zg3lY76OHS1tYWZWVlPcbKyspi//790d7eHuXl5b2Oqa+vj+XLlw/21ACAIbBz586YOHHigNzXoIdLRPQ6S3Lo6tThzp4sWbIk6urqum93dHTEqaeeGjt37oySkpLBmygAMGA6Oztj0qRJ8eUvf3nA7nPQw+Xkk0+Otra2HmO7d++OgoKCGDduXJ/HFBUVRVFRUa/xkpIS4QIAiRnIt3kM+ve4zJ49OxobG3uMrV+/PiorK/t8fwsAwOHkHC4ff/xxbNmyJbZs2RIRn33cecuWLdHS0hIRn13mWbBgQff+tbW18e6770ZdXV1s27YtVq9eHatWrYrbbrttYJ4BADBq5HypaNOmTXHRRRd13z70XpTrrrsunnzyyWhtbe2OmIiIKVOmRENDQyxevDgeeeSRmDBhQjz00EPxrW99awCmDwCMJl/oe1yGSmdnZ5SWlkZHR4f3uABAIgbj9dtvFQEAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkIx+hcuKFStiypQpUVxcHBUVFdHU1PS5+69ZsybOO++8OPbYY6O8vDxuuOGG2LNnT78mDACMXjmHy9q1a2PRokWxdOnSaG5ujurq6pg7d260tLT0uf+rr74aCxYsiBtvvDHeeuutePbZZ+Ovf/1r3HTTTV948gDA6JJzuDzwwANx4403xk033RTTpk2L//u//4tJkybFypUr+9z/T3/6U5x22mmxcOHCmDJlSnzjG9+Im2++OTZt2vSFJw8AjC45hcu+ffti8+bNUVNT02O8pqYmNm7c2OcxVVVVsWvXrmhoaIgsy+KDDz6I5557Lq644orDPk5XV1d0dnb22AAAcgqX9vb2OHDgQJSVlfUYLysri7a2tj6PqaqqijVr1sT8+fOjsLAwTj755Dj++OPjl7/85WEfp76+PkpLS7u3SZMm5TJNAGCE6tebc/Py8nrczrKs19ghW7dujYULF8Zdd90Vmzdvjpdffjl27NgRtbW1h73/JUuWREdHR/e2c+fO/kwTABhhCnLZefz48ZGfn9/r7Mru3bt7nYU5pL6+PubMmRO33357RESce+65cdxxx0V1dXXcc889UV5e3uuYoqKiKCoqymVqAMAokNMZl8LCwqioqIjGxsYe442NjVFVVdXnMZ9++mmMGdPzYfLz8yPiszM1AABHKudLRXV1dfH444/H6tWrY9u2bbF48eJoaWnpvvSzZMmSWLBgQff+V155Zaxbty5WrlwZ27dvj9deey0WLlwYM2fOjAkTJgzcMwEARrycLhVFRMyfPz/27NkTd999d7S2tsb06dOjoaEhJk+eHBERra2tPb7T5frrr4+9e/fGww8/HD/60Y/i+OOPj4svvjjuvffegXsWAMCokJclcL2ms7MzSktLo6OjI0pKSoZ7OgDAERiM12+/VQQAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDL6FS4rVqyIKVOmRHFxcVRUVERTU9Pn7t/V1RVLly6NyZMnR1FRUZx++umxevXqfk0YABi9CnI9YO3atbFo0aJYsWJFzJkzJ371q1/F3LlzY+vWrXHqqaf2eczVV18dH3zwQaxatSq+8pWvxO7du2P//v1fePIAwOiSl2VZlssBs2bNihkzZsTKlSu7x6ZNmxbz5s2L+vr6Xvu//PLL8Z3vfCe2b98eJ5xwQr8m2dnZGaWlpdHR0RElJSX9ug8AYGgNxut3TpeK9u3bF5s3b46ampoe4zU1NbFx48Y+j3nppZeisrIy7rvvvjjllFPizDPPjNtuuy3++c9/HvZxurq6orOzs8cGAJDTpaL29vY4cOBAlJWV9RgvKyuLtra2Po/Zvn17vPrqq1FcXBwvvPBCtLe3x/e///348MMPD/s+l/r6+li+fHkuUwMARoF+vTk3Ly+vx+0sy3qNHXLw4MHIy8uLNWvWxMyZM+Pyyy+PBx54IJ588snDnnVZsmRJdHR0dG87d+7szzQBgBEmpzMu48ePj/z8/F5nV3bv3t3rLMwh5eXlccopp0RpaWn32LRp0yLLsti1a1ecccYZvY4pKiqKoqKiXKYGAIwCOZ1xKSwsjIqKimhsbOwx3tjYGFVVVX0eM2fOnHj//ffj448/7h57++23Y8yYMTFx4sR+TBkAGK1yvlRUV1cXjz/+eKxevTq2bdsWixcvjpaWlqitrY2Izy7zLFiwoHv/a665JsaNGxc33HBDbN26NV555ZW4/fbb43vf+14cc8wxA/dMAIARL+fvcZk/f37s2bMn7r777mhtbY3p06dHQ0NDTJ48OSIiWltbo6WlpXv/L33pS9HY2Bg//OEPo7KyMsaNGxdXX3113HPPPQP3LACAUSHn73EZDr7HBQDSM+zf4wIAMJyECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACSjX+GyYsWKmDJlShQXF0dFRUU0NTUd0XGvvfZaFBQUxPnnn9+fhwUARrmcw2Xt2rWxaNGiWLp0aTQ3N0d1dXXMnTs3WlpaPve4jo6OWLBgQXzzm9/s92QBgNEtL8uyLJcDZs2aFTNmzIiVK1d2j02bNi3mzZsX9fX1hz3uO9/5TpxxxhmRn58fL774YmzZsuWw+3Z1dUVXV1f37c7Ozpg0aVJ0dHRESUlJLtMFAIZJZ2dnlJaWDujrd05nXPbt2xebN2+OmpqaHuM1NTWxcePGwx73xBNPxDvvvBPLli07osepr6+P0tLS7m3SpEm5TBMAGKFyCpf29vY4cOBAlJWV9RgvKyuLtra2Po/5+9//HnfeeWesWbMmCgoKjuhxlixZEh0dHd3bzp07c5kmADBCHVlJ/Je8vLwet7Ms6zUWEXHgwIG45pprYvny5XHmmWce8f0XFRVFUVFRf6YGAIxgOYXL+PHjIz8/v9fZld27d/c6CxMRsXfv3ti0aVM0NzfHLbfcEhERBw8ejCzLoqCgINavXx8XX3zxF5g+ADCa5HSpqLCwMCoqKqKxsbHHeGNjY1RVVfXav6SkJN58883YsmVL91ZbWxtf/epXY8uWLTFr1qwvNnsAYFTJ+VJRXV1dXHvttVFZWRmzZ8+OX//619HS0hK1tbUR8dn7U95777146qmnYsyYMTF9+vQex5900klRXFzcaxwA4H/JOVzmz58fe/bsibvvvjtaW1tj+vTp0dDQEJMnT46IiNbW1v/5nS4AAP2R8/e4DIfB+Bw4ADC4hv17XAAAhpNwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGT0K1xWrFgRU6ZMieLi4qioqIimpqbD7rtu3bq49NJL48QTT4ySkpKYPXt2/P73v+/3hAGA0SvncFm7dm0sWrQoli5dGs3NzVFdXR1z586NlpaWPvd/5ZVX4tJLL42GhobYvHlzXHTRRXHllVdGc3PzF548ADC65GVZluVywKxZs2LGjBmxcuXK7rFp06bFvHnzor6+/oju45xzzon58+fHXXfd1ec/7+rqiq6uru7bnZ2dMWnSpOjo6IiSkpJcpgsADJPOzs4oLS0d0NfvnM647Nu3LzZv3hw1NTU9xmtqamLjxo1HdB8HDx6MvXv3xgknnHDYferr66O0tLR7mzRpUi7TBABGqJzCpb29PQ4cOBBlZWU9xsvKyqKtre2I7uP++++PTz75JK6++urD7rNkyZLo6Ojo3nbu3JnLNAGAEaqgPwfl5eX1uJ1lWa+xvjzzzDPxs5/9LH7729/GSSeddNj9ioqKoqioqD9TAwBGsJzCZfz48ZGfn9/r7Mru3bt7nYX5b2vXro0bb7wxnn322bjkkktynykAMOrldKmosLAwKioqorGxscd4Y2NjVFVVHfa4Z555Jq6//vp4+umn44orrujfTAGAUS/nS0V1dXVx7bXXRmVlZcyePTt+/etfR0tLS9TW1kbEZ+9Pee+99+Kpp56KiM+iZcGCBfHggw/G17/+9e6zNcccc0yUlpYO4FMBAEa6nMNl/vz5sWfPnrj77rujtbU1pk+fHg0NDTF58uSIiGhtbe3xnS6/+tWvYv/+/fGDH/wgfvCDH3SPX3fddfHkk09+8WcAAIwaOX+Py3AYjM+BAwCDa9i/xwUAYDgJFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEhGv8JlxYoVMWXKlCguLo6Kiopoamr63P03bNgQFRUVUVxcHFOnTo1HH320X5MFAEa3nMNl7dq1sWjRoli6dGk0NzdHdXV1zJ07N1paWvrcf8eOHXH55ZdHdXV1NDc3x09+8pNYuHBhPP/881948gDA6JKXZVmWywGzZs2KGTNmxMqVK7vHpk2bFvPmzYv6+vpe+99xxx3x0ksvxbZt27rHamtr44033ojXX3+9z8fo6uqKrq6u7tsdHR1x6qmnxs6dO6OkpCSX6QIAw6SzszMmTZoUH330UZSWlg7MnWY56OrqyvLz87N169b1GF+4cGF2wQUX9HlMdXV1tnDhwh5j69atywoKCrJ9+/b1ecyyZcuyiLDZbDabzTYCtnfeeSeX3PhcBZGD9vb2OHDgQJSVlfUYLysri7a2tj6PaWtr63P//fv3R3t7e5SXl/c6ZsmSJVFXV9d9+6OPPorJkydHS0vLwBUb/XKonp39Gn7W4uhhLY4u1uPoceiKyQknnDBg95lTuBySl5fX43aWZb3G/tf+fY0fUlRUFEVFRb3GS0tL/Ut4lCgpKbEWRwlrcfSwFkcX63H0GDNm4D7EnNM9jR8/PvLz83udXdm9e3evsyqHnHzyyX3uX1BQEOPGjctxugDAaJZTuBQWFkZFRUU0Njb2GG9sbIyqqqo+j5k9e3av/devXx+VlZUxduzYHKcLAIxmOZ+7qauri8cffzxWr14d27Zti8WLF0dLS0vU1tZGxGfvT1mwYEH3/rW1tfHuu+9GXV1dbNu2LVavXh2rVq2K22677Ygfs6ioKJYtW9bn5SOGlrU4eliLo4e1OLpYj6PHYKxFzh+HjvjsC+juu+++aG1tjenTp8cvfvGLuOCCCyIi4vrrr49//OMf8cc//rF7/w0bNsTixYvjrbfeigkTJsQdd9zRHToAAEeqX+ECADAc/FYRAJAM4QIAJEO4AADJEC4AQDKOmnBZsWJFTJkyJYqLi6OioiKampo+d/8NGzZERUVFFBcXx9SpU+PRRx8dopmOfLmsxbp16+LSSy+NE088MUpKSmL27Nnx+9//fghnO7Ll+ndxyGuvvRYFBQVx/vnnD+4ER5Fc16KrqyuWLl0akydPjqKiojj99NNj9erVQzTbkS3XtVizZk2cd955ceyxx0Z5eXnccMMNsWfPniGa7cj1yiuvxJVXXhkTJkyIvLy8ePHFF//nMQPy2j1gv3r0BfzmN7/Jxo4dmz322GPZ1q1bs1tvvTU77rjjsnfffbfP/bdv354de+yx2a233ppt3bo1e+yxx7KxY8dmzz333BDPfOTJdS1uvfXW7N57783+8pe/ZG+//Xa2ZMmSbOzYsdnf/va3IZ75yJPrWhzy0UcfZVOnTs1qamqy8847b2gmO8L1Zy2uuuqqbNasWVljY2O2Y8eO7M9//nP22muvDeGsR6Zc16KpqSkbM2ZM9uCDD2bbt2/PmpqasnPOOSebN2/eEM985GloaMiWLl2aPf/881lEZC+88MLn7j9Qr91HRbjMnDkzq62t7TF21llnZXfeeWef+//4xz/OzjrrrB5jN998c/b1r3990OY4WuS6Fn05++yzs+XLlw/01Ead/q7F/Pnzs5/+9KfZsmXLhMsAyXUtfve732WlpaXZnj17hmJ6o0qua/Hzn/88mzp1ao+xhx56KJs4ceKgzXE0OpJwGajX7mG/VLRv377YvHlz1NTU9BivqamJjRs39nnM66+/3mv/yy67LDZt2hT//ve/B22uI11/1uK/HTx4MPbu3TugvwQ6GvV3LZ544ol45513YtmyZYM9xVGjP2vx0ksvRWVlZdx3331xyimnxJlnnhm33XZb/POf/xyKKY9Y/VmLqqqq2LVrVzQ0NESWZfHBBx/Ec889F1dcccVQTJn/MFCv3f36deiB1N7eHgcOHOj1I41lZWW9fpzxkLa2tj73379/f7S3t0d5efmgzXck689a/Lf7778/Pvnkk7j66qsHY4qjRn/W4u9//3vceeed0dTUFAUFw/6nPWL0Zy22b98er776ahQXF8cLL7wQ7e3t8f3vfz8+/PBD73P5AvqzFlVVVbFmzZqYP39+/Otf/4r9+/fHVVddFb/85S+HYsr8h4F67R72My6H5OXl9bidZVmvsf+1f1/j5C7XtTjkmWeeiZ/97Gexdu3aOOmkkwZreqPKka7FgQMH4pprronly5fHmWeeOVTTG1Vy+bs4ePBg5OXlxZo1a2LmzJlx+eWXxwMPPBBPPvmksy4DIJe12Lp1ayxcuDDuuuuu2Lx5c7z88suxY8cOPzszTAbitXvY/7ds/PjxkZ+f36uWd+/e3avMDjn55JP73L+goCDGjRs3aHMd6fqzFoesXbs2brzxxnj22WfjkksuGcxpjgq5rsXevXtj06ZN0dzcHLfccktEfPbimWVZFBQUxPr16+Piiy8ekrmPNP35uygvL49TTjklSktLu8emTZsWWZbFrl274owzzhjUOY9U/VmL+vr6mDNnTtx+++0REXHuuefGcccdF9XV1XHPPfc4Qz+EBuq1e9jPuBQWFkZFRUU0Njb2GG9sbIyqqqo+j5k9e3av/devXx+VlZUxduzYQZvrSNeftYj47EzL9ddfH08//bTrxgMk17UoKSmJN998M7Zs2dK91dbWxle/+tXYsmVLzJo1a6imPuL05+9izpw58f7778fHH3/cPfb222/HmDFjYuLEiYM635GsP2vx6aefxpgxPV/q8vPzI+L//98+Q2PAXrtzeivvIDn08bZVq1ZlW7duzRYtWpQdd9xx2T/+8Y8sy7LszjvvzK699tru/Q99pGrx4sXZ1q1bs1WrVvk49ADJdS2efvrprKCgIHvkkUey1tbW7u2jjz4arqcwYuS6Fv/Np4oGTq5rsXfv3mzixInZt7/97eytt97KNmzYkJ1xxhnZTTfdNFxPYcTIdS2eeOKJrKCgIFuxYkX2zjvvZK+++mpWWVmZzZw5c7iewoixd+/erLm5OWtubs4iInvggQey5ubm7o+mD9Zr91ERLlmWZY888kg2efLkrLCwMJsxY0a2YcOG7n923XXXZRdeeGGP/f/4xz9mX/va17LCwsLstNNOy1auXDnEMx65clmLCy+8MIuIXtt111039BMfgXL9u/hPwmVg5boW27Ztyy655JLsmGOOySZOnJjV1dVln3766RDPemTKdS0eeuih7Oyzz86OOeaYrLy8PPvud7+b7dq1a4hnPfL84Q9/+Nz//g/Wa3deljlXBgCkYdjf4wIAcKSECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJOP/Aa0FoYwT/urPAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(0,50),model.history.history['f1_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.5671641 , 0.5091863 , 0.24999994, 0.02272726, 0.2765957 ,\n",
       "        0.54088044, 0.59649116, 0.        , 0.37914687, 0.11891886],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.7205387 , 0.7092198 , 0.56459326, 0.5274725 , 0.8169013 ,\n",
       "        0.89230764, 0.88235295, 0.3908046 , 0.62962955, 0.13207546],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.7575757 , 0.7537313 , 0.6903553 , 0.5766871 , 0.8652482 ,\n",
       "        0.9222798 , 0.92307687, 0.67692304, 0.8191489 , 0.34831455],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.77655673, 0.77647054, 0.75490195, 0.6626506 , 0.8510638 ,\n",
       "        0.90052354, 0.92307687, 0.7625899 , 0.8571428 , 0.40449435],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.79693484, 0.78260857, 0.7804877 , 0.75471693, 0.9264705 ,\n",
       "        0.964467  , 0.9384614 , 0.84285706, 0.90109885, 0.48677245],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.80303025, 0.806324  , 0.81773394, 0.78823525, 0.9352517 ,\n",
       "        0.9693877 , 0.96124023, 0.87218046, 0.9032258 , 0.55865914],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.8125    , 0.8015872 , 0.81553394, 0.8383233 , 0.9352517 ,\n",
       "        0.9690721 , 0.9302325 , 0.9037037 , 0.91208786, 0.55208325],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.83823526, 0.8259109 , 0.83412313, 0.8414633 , 0.9352517 ,\n",
       "        0.9743589 , 0.98437494, 0.8840579 , 0.92737424, 0.5810055 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.80952376, 0.816     , 0.8502415 , 0.8742515 , 0.9565217 ,\n",
       "        0.9795917 , 0.96124023, 0.93129766, 0.9513513 , 0.609137  ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.86486477, 0.83739835, 0.86511624, 0.9069767 , 0.97101444,\n",
       "        0.98969066, 0.97637784, 0.9558823 , 0.9777778 , 0.6594594 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.8333333 , 0.82730913, 0.85990334, 0.91124254, 0.9857142 ,\n",
       "        0.98969066, 0.98437494, 0.9565217 , 0.98888886, 0.6229508 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.876923  , 0.83794457, 0.8815165 , 0.92941177, 0.9496403 ,\n",
       "        0.9795917 , 0.97637784, 0.962963  , 0.97237563, 0.68888885],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.8837209 , 0.86746985, 0.88679236, 0.917647  , 0.98550713,\n",
       "        1.        , 0.9846153 , 0.9701493 , 0.9834253 , 0.70967734],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.88549614, 0.8663967 , 0.9107981 , 0.9221557 , 0.9857142 ,\n",
       "        0.98969066, 0.98437494, 0.96350354, 0.9780219 , 0.7362637 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.87969923, 0.85950416, 0.89908254, 0.917647  , 0.9787233 ,\n",
       "        0.98969066, 0.9921259 , 0.9558823 , 0.972067  , 0.72625697],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.88715947, 0.8594377 , 0.89523804, 0.9523809 , 0.8985507 ,\n",
       "        0.9435896 , 0.9606299 , 0.9640288 , 0.98888886, 0.75132275],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9070631 , 0.8688524 , 0.89523804, 0.9461076 , 0.96453893,\n",
       "        0.9740932 , 0.98437494, 0.9411764 , 0.9555555 , 0.7826086 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.89230764, 0.9003983 , 0.9333332 , 0.9461076 , 0.97841716,\n",
       "        0.9846153 , 1.        , 0.9777777 , 0.96739125, 0.7759562 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.8999999 , 0.8951612 , 0.91428566, 0.9404761 , 1.        ,\n",
       "        1.        , 1.        , 0.98550713, 0.98888886, 0.78494626],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.90225554, 0.88888884, 0.9134615 , 0.9523809 , 1.        ,\n",
       "        1.        , 1.        , 0.98529404, 0.98901093, 0.7865167 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9049429 , 0.88799995, 0.9178744 , 0.9212121 , 1.        ,\n",
       "        1.        , 1.        , 0.9927007 , 0.99447507, 0.7914438 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9213483 , 0.8915662 , 0.92452824, 0.9700598 , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.99447507, 0.8314606 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9283018 , 0.87999994, 0.9569378 , 0.9575757 , 0.99290776,\n",
       "        1.        , 0.9921259 , 0.9927007 , 1.        , 0.78021973],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.92720294, 0.9105691 , 0.9345794 , 0.9707602 , 1.        ,\n",
       "        1.        , 1.        , 0.9927007 , 0.99447507, 0.8444444 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.94339615, 0.93700784, 0.9615384 , 0.9761904 , 0.9928057 ,\n",
       "        0.99487174, 1.        , 1.        , 1.        , 0.87005645],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9473683 , 0.9317268 , 0.9615384 , 0.98823524, 0.99290776,\n",
       "        0.99481857, 1.        , 1.        , 0.99447507, 0.86666656],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.92424244, 0.9411764 , 0.961165  , 0.9642856 , 0.9928057 ,\n",
       "        0.99487174, 1.        , 1.        , 1.        , 0.8491619 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9318181 , 0.95238084, 0.9711538 , 0.98795176, 0.9857142 ,\n",
       "        0.98969066, 1.        , 1.        , 0.99447507, 0.8524589 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9389312 , 0.9285714 , 0.96650714, 0.98823524, 0.9857142 ,\n",
       "        0.98969066, 1.        , 1.        , 0.99447507, 0.8444444 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.90298504, 0.9322709 , 0.9711538 , 0.9764705 , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.8342856 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9384614, 0.9249011, 0.9805825, 0.9820358, 1.       , 1.       ,\n",
       "        1.       , 1.       , 1.       , 0.827957 ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9615384 , 0.95312494, 0.9805825 , 0.9822485 , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.9060773 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.94505495, 0.972332  , 0.9853658 , 0.9940828 , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.8837209 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9302325 , 0.9606298 , 0.98550713, 0.98809516, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.85405403],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9288389 , 0.9317268 , 0.9711538 , 0.98809516, 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.99453545, 0.82681555],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9312977 , 0.9359999 , 0.96650714, 0.95906425, 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.98888886, 0.84615374],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9621211 , 0.95238084, 0.9805825 , 0.9940828 , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.8950275 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9770992 , 0.9685039 , 0.99516904, 0.9940828 , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.9222222 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9696969 , 0.98023707, 0.9951219 , 0.98809516, 0.9857142 ,\n",
       "        0.98969066, 1.        , 1.        , 1.        , 0.92307687],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9770992 , 0.9554655 , 0.97607654, 0.98809516, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.9247312 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9581748 , 0.9841269 , 1.        , 0.9940828 , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.91208786],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9657794, 0.9721115, 0.9807692, 1.       , 1.       , 1.       ,\n",
       "        1.       , 1.       , 1.       , 0.9340659], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9770992 , 0.9599999 , 0.96618354, 0.9940828 , 1.        ,\n",
       "        1.        , 0.98437494, 0.9925925 , 1.        , 0.92972976],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9541984 , 0.96874994, 0.9509803 , 0.9940828 , 0.99290776,\n",
       "        1.        , 0.9439999 , 0.97058815, 0.99453545, 0.92307687],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.97358483, 0.9482071 , 0.942857  , 0.98823524, 0.8714285 ,\n",
       "        0.92708325, 0.9302325 , 0.95522386, 0.9834253 , 0.91111106],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9806949 , 0.9638553 , 0.9411764 , 0.97041416, 0.9640287 ,\n",
       "        0.9743589 , 0.9618319 , 0.97058815, 0.9836065 , 0.9304812 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9538461 , 0.9647058 , 0.951923  , 0.9454545 , 0.9428571 ,\n",
       "        0.9687499 , 0.9384614 , 0.97058815, 0.9834253 , 0.8864865 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9541984 , 0.9599999 , 0.9708737 , 0.9764705 , 0.8999999 ,\n",
       "        0.9222798 , 0.9921259 , 1.        , 0.99447507, 0.89839566],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9621211 , 0.96414334, 0.99516904, 0.9761904 , 0.9787233 ,\n",
       "        0.9844558 , 1.        , 0.9925925 , 0.99453545, 0.9010989 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9621211 , 0.9761905 , 0.9951219 , 0.9822485 , 0.9640287 ,\n",
       "        0.9743589 , 1.        , 1.        , 1.        , 0.92307687],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9694656 , 0.9842519 , 1.        , 0.9940828 , 0.98550713,\n",
       "        0.98979586, 1.        , 1.        , 1.        , 0.92817676],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.973384  , 0.9800796 , 0.99516904, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.9398907 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9846153 , 0.9880477 , 1.        , 0.9940828 , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.95698917],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9809885 , 0.99601585, 0.9951219 , 0.98823524, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.96174854],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.98473275, 0.96799994, 1.        , 0.9940119 , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.9304812 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([1.        , 0.99206346, 1.        , 0.9940828 , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.98360646],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.99616855, 0.98814225, 0.9951219 , 0.9820358 , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.96774185],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.98113203, 0.9761905 , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.93922645],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9885056 , 0.99601585, 1.        , 0.9940828 , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.9729729 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9885056 , 0.99601585, 0.9951219 , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.9839572 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9885931 , 0.99601585, 1.        , 0.9940119 , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.9729729 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9809885 , 0.9919999 , 0.99516904, 0.98809516, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.95652163],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.96551716, 0.98399997, 0.9951219 , 0.98809516, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.9255319 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.99242413, 0.99206346, 1.        , 0.98809516, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.9670329 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9809885 , 0.99601585, 1.        , 0.9940119 , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.9621621 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9808428 , 0.99601585, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.96774185],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9885931 , 0.99601585, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.97826076],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.98841697, 0.99601585, 1.        , 0.9940828 , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.973262  ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9477612 , 0.9919999 , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.91111106],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9692307 , 0.98814225, 0.99019605, 0.9940828 , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.9462365 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9809885 , 0.99601585, 1.        , 0.98809516, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.95652163],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.98841697, 0.9919999 , 0.9902912 , 0.9940828 , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.9787234 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9923664 , 0.9880477 , 0.9853658 , 0.96385545, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.95744675],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9538461 , 0.96414334, 0.9902912 , 0.9820358 , 1.        ,\n",
       "        1.        , 1.        , 0.9925925 , 0.98901093, 0.8888888 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9770992 , 0.902439  , 0.9186603 , 0.9822485 , 1.        ,\n",
       "        0.99481857, 1.        , 0.9781021 , 0.9726775 , 0.9189189 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9498069 , 0.9365078 , 0.96618354, 0.98809516, 0.9857142 ,\n",
       "        0.99487174, 0.9921259 , 0.97058815, 0.9555555 , 0.9042553 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.96603763, 0.96442676, 0.98522156, 1.        , 1.        ,\n",
       "        1.        , 0.99224806, 1.        , 0.99453545, 0.92817676],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9809885 , 0.9685039 , 0.9805825 , 1.        , 1.        ,\n",
       "        1.        , 0.98437494, 0.98529404, 0.98888886, 0.96174854],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.97318   , 0.99598384, 1.        , 0.98809516, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.94680846],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9809885 , 1.        , 1.        , 0.9940119 , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.96774185],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9923664 , 0.99601585, 0.9951219 , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.98924726],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([1.        , 0.99601585, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.9945945 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9923664 , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.98924726],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.99616855, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.99465233],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.99616855, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.99465233],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.99616855, 0.99601585, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.98924726],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9885056, 1.       , 1.       , 1.       , 1.       , 1.       ,\n",
       "        1.       , 1.       , 1.       , 0.9839572], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9923664 , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.98924726],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9923664 , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.98924726],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.9885931, 1.       , 1.       , 1.       , 1.       , 1.       ,\n",
       "        1.       , 1.       , 1.       , 0.9837837], dtype=float32)>]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history['f1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step\n"
     ]
    }
   ],
   "source": [
    "y_res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True, False, ..., False, False, False],\n",
       "       [ True, False, False, ..., False, False, False],\n",
       "       [False,  True, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ...,  True, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res>0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res = np.argmax(y_res, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 6, 4, 8, 3, 7, 0, 9, 3, 8, 0, 1, 4, 0, 5, 0, 1, 2, 1, 0,\n",
       "       5, 9, 1, 9, 9, 7, 0, 2, 1, 9, 2, 8, 4, 8, 9, 6, 0, 4, 3, 4, 5, 8,\n",
       "       2, 3, 1, 8, 7, 5, 6, 7, 2, 6, 0, 2, 5, 0, 3, 2, 0, 2, 7, 9, 9, 0,\n",
       "       0, 2, 8, 4, 5, 3, 0, 0, 8, 9, 8, 3, 5, 7, 0, 0, 9, 8, 0, 0, 6, 2,\n",
       "       8, 0, 2, 2, 8, 5, 9, 3, 9, 1, 5, 1, 6, 2, 2, 7, 1, 0, 9, 1, 3, 3,\n",
       "       9, 4, 8, 1, 1, 6, 2, 3, 1, 0, 5, 5, 4, 2, 9, 6, 5, 2, 3, 3, 1, 1,\n",
       "       0, 2, 8, 1, 5, 3, 9, 2, 3, 1, 0, 5, 0, 1, 5, 2, 0, 5, 5, 7, 6, 4,\n",
       "       6, 9, 0, 0, 0, 9, 3, 0, 7, 6, 3, 0, 3, 7, 6, 1, 2, 4, 0, 3, 8, 2,\n",
       "       1, 5, 3, 3, 6, 3, 1, 4, 9, 9, 9, 7, 9, 9, 6, 3, 3, 4, 8, 1, 4, 2,\n",
       "       1, 7, 5, 8, 8, 3, 9, 5, 1, 1, 2, 8, 0, 6, 6, 3, 7, 2, 9, 9, 7, 4,\n",
       "       4, 5, 4, 4, 6, 6, 4, 0, 0, 6, 9, 8, 4, 6, 8, 5, 3, 0, 7, 2, 1, 0,\n",
       "       4, 1, 1, 5, 2, 7, 5, 9, 7, 2, 7, 3, 1, 1, 9, 1, 9, 5, 0, 1, 5, 5,\n",
       "       7, 2, 2, 2, 1, 1, 5, 7, 2, 8, 0, 1, 8, 1, 7, 9, 1, 6, 0, 9, 8, 1,\n",
       "       4, 7, 5, 0, 1, 2, 4, 9, 8, 7, 5, 6, 8, 0, 0, 4, 8, 4, 5, 3, 5, 2,\n",
       "       3, 5, 8, 5, 0, 0, 2, 5, 3, 1, 1, 6, 9, 6, 1, 0, 8, 2, 4, 5, 4, 8,\n",
       "       8, 2, 3, 1, 0, 9, 7, 2, 8, 3, 6, 7, 3])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88        48\n",
      "           1       0.84      0.84      0.84        45\n",
      "           2       0.89      0.85      0.87        40\n",
      "           3       0.56      0.79      0.66        24\n",
      "           4       0.88      1.00      0.94        23\n",
      "           5       0.94      0.87      0.91        39\n",
      "           6       0.92      0.88      0.90        26\n",
      "           7       0.96      0.77      0.86        31\n",
      "           8       0.88      0.93      0.90        30\n",
      "           9       0.71      0.68      0.69        37\n",
      "\n",
      "    accuracy                           0.85       343\n",
      "   macro avg       0.85      0.85      0.85       343\n",
      "weighted avg       0.86      0.85      0.85       343\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_res, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KTF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
